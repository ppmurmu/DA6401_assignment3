{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-20T09:30:58.400439Z",
     "iopub.status.busy": "2025-05-20T09:30:58.400184Z",
     "iopub.status.idle": "2025-05-20T09:31:05.611007Z",
     "shell.execute_reply": "2025-05-20T09:31:05.610365Z",
     "shell.execute_reply.started": "2025-05-20T09:30:58.400419Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T09:31:07.653467Z",
     "iopub.status.busy": "2025-05-20T09:31:07.652688Z",
     "iopub.status.idle": "2025-05-20T09:31:07.913248Z",
     "shell.execute_reply": "2025-05-20T09:31:07.912708Z",
     "shell.execute_reply.started": "2025-05-20T09:31:07.653431Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T09:31:10.683552Z",
     "iopub.status.busy": "2025-05-20T09:31:10.683172Z",
     "iopub.status.idle": "2025-05-20T09:31:10.695635Z",
     "shell.execute_reply": "2025-05-20T09:31:10.694977Z",
     "shell.execute_reply.started": "2025-05-20T09:31:10.683529Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TransliterationDataset(Dataset):\n",
    "    def __init__(self, file_path, latin_vocab=None, devanagari_vocab=None, max_len=50):\n",
    "\n",
    "        # Read the file and check the number of columns\n",
    "        self.data = pd.read_csv(file_path, sep='\\t', header=None)\n",
    "        \n",
    "        # Adjust based on the number of columns in the data\n",
    "        if self.data.shape[1] == 2:\n",
    "            self.data.columns = ['devanagari', 'latin']\n",
    "        elif self.data.shape[1] == 3:\n",
    "            # Based on the screenshot, format is: [Devanagari, Latin, Frequency]\n",
    "            self.data.columns = ['devanagari', 'latin', 'frequency']\n",
    "        else:\n",
    "            # Try to infer based on first row\n",
    "            print(f\"Warning: Unexpected number of columns ({self.data.shape[1]}). Inspecting first row:\")\n",
    "            print(self.data.iloc[0].tolist())\n",
    "            # Default naming\n",
    "            self.data.columns = [f'col{i}' for i in range(self.data.shape[1])]\n",
    "        \n",
    "        \n",
    "        # Filter out rows with sequences longer than max_len\n",
    "        self.data = self.data[\n",
    "            (self.data['latin'].str.len() <= max_len) & \n",
    "            (self.data['devanagari'].str.len() <= max_len)\n",
    "        ]\n",
    "        \n",
    "        # Define special tokens BEFORE creating vocabularies\n",
    "        self.PAD_TOKEN = '<PAD>'\n",
    "        self.SOS_TOKEN = '<SOS>'\n",
    "        self.EOS_TOKEN = '<EOS>'\n",
    "        \n",
    "        self.PAD_IDX = 0\n",
    "        self.SOS_IDX = 1\n",
    "        self.EOS_IDX = 2\n",
    "        \n",
    "        # Create or use provided vocabularies\n",
    "        if latin_vocab is None:\n",
    "            # Create a new vocabulary\n",
    "            char_to_idx = self._create_vocab(self.data['latin'])\n",
    "            # Add special tokens\n",
    "            self.latin_vocab = {\n",
    "                self.PAD_TOKEN: self.PAD_IDX,\n",
    "                self.SOS_TOKEN: self.SOS_IDX,\n",
    "                self.EOS_TOKEN: self.EOS_IDX\n",
    "            }\n",
    "            # Add character tokens with indices starting after special tokens\n",
    "            for char, idx in char_to_idx.items():\n",
    "                self.latin_vocab[char] = idx + 3\n",
    "        else:\n",
    "            # Use the provided vocabulary\n",
    "            self.latin_vocab = latin_vocab\n",
    "            \n",
    "        if devanagari_vocab is None:\n",
    "            # Create a new vocabulary\n",
    "            char_to_idx = self._create_vocab(self.data['devanagari'])\n",
    "            # Add special tokens\n",
    "            self.devanagari_vocab = {\n",
    "                self.PAD_TOKEN: self.PAD_IDX,\n",
    "                self.SOS_TOKEN: self.SOS_IDX,\n",
    "                self.EOS_TOKEN: self.EOS_IDX\n",
    "            }\n",
    "            # Add character tokens with indices starting after special tokens\n",
    "            for char, idx in char_to_idx.items():\n",
    "                self.devanagari_vocab[char] = idx + 3\n",
    "        else:\n",
    "            # Use the provided vocabulary\n",
    "            self.devanagari_vocab = devanagari_vocab\n",
    "            \n",
    "        # Create reverse mappings (index to character)\n",
    "        self.latin_idx2char = {idx: char for char, idx in self.latin_vocab.items()}\n",
    "        self.devanagari_idx2char = {idx: char for char, idx in self.devanagari_vocab.items()}\n",
    "        \n",
    "        # Print vocabulary sizes and special token information\n",
    "        print(f\"Latin vocabulary size: {len(self.latin_vocab)}\")\n",
    "        print(f\"Devanagari vocabulary size: {len(self.devanagari_vocab)}\")\n",
    "        print(f\"Special tokens: PAD={self.PAD_TOKEN} (idx={self.PAD_IDX}), \"\n",
    "              f\"SOS={self.SOS_TOKEN} (idx={self.SOS_IDX}), \"\n",
    "              f\"EOS={self.EOS_TOKEN} (idx={self.EOS_IDX})\")\n",
    "    \n",
    "    def _create_vocab(self, series):\n",
    "        \"\"\"Create vocabulary from series of strings\"\"\"\n",
    "        chars = set()\n",
    "        for s in series:\n",
    "            chars.update(s)\n",
    "        return {char: idx for idx, char in enumerate(sorted(chars))}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        latin_word = self.data.iloc[idx]['latin']\n",
    "        devanagari_word = self.data.iloc[idx]['devanagari']\n",
    "        \n",
    "        # Convert to indices\n",
    "        latin_indices = [self.latin_vocab[char] for char in latin_word]\n",
    "        latin_indices = [self.SOS_IDX] + latin_indices + [self.EOS_IDX]\n",
    "        \n",
    "        devanagari_indices = [self.devanagari_vocab[char] for char in devanagari_word]\n",
    "        devanagari_indices = [self.SOS_IDX] + devanagari_indices + [self.EOS_IDX]\n",
    "        \n",
    "        return {\n",
    "            'latin': torch.tensor(latin_indices),\n",
    "            'devanagari': torch.tensor(devanagari_indices),\n",
    "            'latin_len': len(latin_indices),\n",
    "            'devanagari_len': len(devanagari_indices),\n",
    "            'latin_text': latin_word,\n",
    "            'devanagari_text': devanagari_word\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T09:31:16.931472Z",
     "iopub.status.busy": "2025-05-20T09:31:16.930747Z",
     "iopub.status.idle": "2025-05-20T09:31:16.943502Z",
     "shell.execute_reply": "2025-05-20T09:31:16.942802Z",
     "shell.execute_reply.started": "2025-05-20T09:31:16.931436Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate function for padding sequences in batch\"\"\"\n",
    "    latin_seqs = [item['latin'] for item in batch]\n",
    "    devanagari_seqs = [item['devanagari'] for item in batch]\n",
    "    latin_lens = torch.tensor([item['latin_len'] for item in batch])\n",
    "    devanagari_lens = torch.tensor([item['devanagari_len'] for item in batch])\n",
    "\n",
    "    # Pad sequences\n",
    "    latin_padded = pad_sequence(latin_seqs, batch_first=True, padding_value=0)\n",
    "    devanagari_padded = pad_sequence(devanagari_seqs, batch_first=True, padding_value=0)\n",
    "\n",
    "    latin_texts = [item['latin_text'] for item in batch]\n",
    "    devanagari_texts = [item['devanagari_text'] for item in batch]\n",
    "\n",
    "    return {\n",
    "        'latin': latin_padded,\n",
    "        'devanagari': devanagari_padded,\n",
    "        'latin_len': latin_lens,\n",
    "        'devanagari_len': devanagari_lens,\n",
    "        'latin_text': latin_texts,\n",
    "        'devanagari_text': devanagari_texts\n",
    "    }\n",
    "\n",
    "def get_dataloaders(train_path, val_path, test_path, batch_size=32, max_len=50):\n",
    "\n",
    "    # Create train dataset and get vocabularies\n",
    "    train_dataset = TransliterationDataset(train_path, max_len=max_len)\n",
    "\n",
    "    # Create validation and test datasets with train vocabularies\n",
    "    val_dataset = TransliterationDataset(\n",
    "        val_path,\n",
    "        latin_vocab=train_dataset.latin_vocab,\n",
    "        devanagari_vocab=train_dataset.devanagari_vocab,\n",
    "        max_len=max_len\n",
    "    )\n",
    "\n",
    "    test_dataset = TransliterationDataset(\n",
    "        test_path,\n",
    "        latin_vocab=train_dataset.latin_vocab,\n",
    "        devanagari_vocab=train_dataset.devanagari_vocab,\n",
    "        max_len=max_len\n",
    "    )\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'train_loader': train_loader,\n",
    "        'val_loader': val_loader,\n",
    "        'test_loader': test_loader,\n",
    "        'latin_vocab': train_dataset.latin_vocab,\n",
    "        'devanagari_vocab': train_dataset.devanagari_vocab,\n",
    "        'latin_idx2char': train_dataset.latin_idx2char,\n",
    "        'devanagari_idx2char': train_dataset.devanagari_idx2char\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T09:31:20.984264Z",
     "iopub.status.busy": "2025-05-20T09:31:20.983593Z",
     "iopub.status.idle": "2025-05-20T09:31:20.994548Z",
     "shell.execute_reply": "2025-05-20T09:31:20.993796Z",
     "shell.execute_reply.started": "2025-05-20T09:31:20.984231Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers, cell_type='GRU', dropout=0.0):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.cell_type = cell_type\n",
    "\n",
    "        # Character embedding layer\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "\n",
    "        # RNN layer\n",
    "        if cell_type == 'RNN':\n",
    "            self.rnn = nn.RNN(emb_dim, hidden_dim, n_layers, dropout=dropout if n_layers > 1 else 0, batch_first=True)\n",
    "        elif cell_type == 'LSTM':\n",
    "            self.rnn = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout if n_layers > 1 else 0, batch_first=True)\n",
    "        elif cell_type == 'GRU':\n",
    "            self.rnn = nn.GRU(emb_dim, hidden_dim, n_layers, dropout=dropout if n_layers > 1 else 0, batch_first=True)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported RNN cell type: {cell_type}\")\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, src_len):\n",
    "\n",
    "        # Convert to embeddings\n",
    "        embedded = self.dropout(self.embedding(src))  # [batch_size, seq_len, emb_dim]\n",
    "\n",
    "        # Pack sequences to handle variable lengths efficiently\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(\n",
    "            embedded, src_len.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "\n",
    "        # Pass through RNN\n",
    "        if self.cell_type == 'LSTM':\n",
    "            packed_outputs, (hidden, cell) = self.rnn(packed_embedded)\n",
    "            # Unpack sequence\n",
    "            outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs, batch_first=True)\n",
    "            return outputs, (hidden, cell)\n",
    "        else:\n",
    "            packed_outputs, hidden = self.rnn(packed_embedded)\n",
    "            # Unpack sequence\n",
    "            outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs, batch_first=True)\n",
    "            return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T09:31:24.567678Z",
     "iopub.status.busy": "2025-05-20T09:31:24.567167Z",
     "iopub.status.idle": "2025-05-20T09:31:24.574936Z",
     "shell.execute_reply": "2025-05-20T09:31:24.574353Z",
     "shell.execute_reply.started": "2025-05-20T09:31:24.567653Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hidden_dim, n_layers, cell_type='GRU', dropout=0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.cell_type = cell_type\n",
    "\n",
    "        # Character embedding layer\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "\n",
    "        # RNN layer\n",
    "        if cell_type == 'RNN':\n",
    "            self.rnn = nn.RNN(emb_dim, hidden_dim, n_layers, dropout=dropout if n_layers > 1 else 0, batch_first=True)\n",
    "        elif cell_type == 'LSTM':\n",
    "            self.rnn = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout if n_layers > 1 else 0, batch_first=True)\n",
    "        elif cell_type == 'GRU':\n",
    "            self.rnn = nn.GRU(emb_dim, hidden_dim, n_layers, dropout=dropout if n_layers > 1 else 0, batch_first=True)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported RNN cell type: {cell_type}\")\n",
    "\n",
    "        # Linear layer to produce output probabilities\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "\n",
    "        # Convert to embeddings and apply dropout\n",
    "        input = input.unsqueeze(1)  # Add sequence dimension [batch_size, 1]\n",
    "        embedded = self.dropout(self.embedding(input))  # [batch_size, 1, emb_dim]\n",
    "\n",
    "        # Pass through RNN\n",
    "        if self.cell_type == 'LSTM':\n",
    "            output, (hidden, cell) = self.rnn(embedded, hidden)\n",
    "        else:\n",
    "            output, hidden = self.rnn(embedded, hidden)\n",
    "\n",
    "        # Get prediction\n",
    "        prediction = self.fc_out(output.squeeze(1))  # [batch_size, output_dim]\n",
    "\n",
    "        # Return prediction and hidden state\n",
    "        if self.cell_type == 'LSTM':\n",
    "            return prediction, (hidden, cell)\n",
    "        else:\n",
    "            return prediction, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder-Decoder Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T09:31:27.530479Z",
     "iopub.status.busy": "2025-05-20T09:31:27.530210Z",
     "iopub.status.idle": "2025-05-20T09:31:27.538254Z",
     "shell.execute_reply": "2025-05-20T09:31:27.537546Z",
     "shell.execute_reply.started": "2025-05-20T09:31:27.530449Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EncoderDecoderAdapter(nn.Module):\n",
    "    \"\"\"\n",
    "    Adapter module to connect encoder and decoder with different layer counts\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder_layers, decoder_layers, hidden_dim, cell_type):\n",
    "        super().__init__()\n",
    "        self.encoder_layers = encoder_layers\n",
    "        self.decoder_layers = decoder_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.cell_type = cell_type\n",
    "\n",
    "        # Map features: fully-connected network for each decoder layer\n",
    "        self.hidden_adapters = nn.ModuleList([\n",
    "            nn.Linear(encoder_layers * hidden_dim, hidden_dim)\n",
    "            for _ in range(decoder_layers)\n",
    "        ])\n",
    "\n",
    "        # Cell state adapters for LSTM\n",
    "        if cell_type == 'LSTM':\n",
    "            self.cell_adapters = nn.ModuleList([\n",
    "                nn.Linear(encoder_layers * hidden_dim, hidden_dim)\n",
    "                for _ in range(decoder_layers)\n",
    "            ])\n",
    "\n",
    "    def forward(self, encoder_hidden):\n",
    "        \n",
    "        if self.cell_type == 'LSTM':\n",
    "            hidden, cell = encoder_hidden\n",
    "            batch_size = hidden.size(1)\n",
    "\n",
    "            # Reshape to [batch_size, encoder_layers * hidden_dim]\n",
    "            hidden_flat = hidden.permute(1, 0, 2).contiguous().view(batch_size, -1)\n",
    "            cell_flat = cell.permute(1, 0, 2).contiguous().view(batch_size, -1)\n",
    "\n",
    "            # Create new hidden and cell states for decoder\n",
    "            decoder_hidden = []\n",
    "            decoder_cell = []\n",
    "\n",
    "            # Apply adapter networks for each decoder layer\n",
    "            for i in range(self.decoder_layers):\n",
    "                decoder_hidden.append(self.hidden_adapters[i](hidden_flat))\n",
    "                decoder_cell.append(self.cell_adapters[i](cell_flat))\n",
    "\n",
    "            # Stack and reshape to [decoder_layers, batch_size, hidden_dim]\n",
    "            decoder_hidden = torch.stack(decoder_hidden, dim=0)\n",
    "            decoder_cell = torch.stack(decoder_cell, dim=0)\n",
    "\n",
    "            return (decoder_hidden, decoder_cell)\n",
    "\n",
    "        else:  # RNN or GRU\n",
    "            batch_size = encoder_hidden.size(1)\n",
    "\n",
    "            # Reshape to [batch_size, encoder_layers * hidden_dim]\n",
    "            hidden_flat = encoder_hidden.permute(1, 0, 2).contiguous().view(batch_size, -1)\n",
    "\n",
    "            # Create new hidden state for decoder\n",
    "            decoder_hidden = []\n",
    "\n",
    "            # Apply adapter networks for each decoder layer\n",
    "            for i in range(self.decoder_layers):\n",
    "                decoder_hidden.append(self.hidden_adapters[i](hidden_flat))\n",
    "\n",
    "            # Stack and reshape to [decoder_layers, batch_size, hidden_dim]\n",
    "            decoder_hidden = torch.stack(decoder_hidden, dim=0)\n",
    "\n",
    "            return decoder_hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T09:31:31.027262Z",
     "iopub.status.busy": "2025-05-20T09:31:31.026993Z",
     "iopub.status.idle": "2025-05-20T09:31:31.035408Z",
     "shell.execute_reply": "2025-05-20T09:31:31.034849Z",
     "shell.execute_reply.started": "2025-05-20T09:31:31.027243Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device, teacher_forcing_ratio=0.5):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "\n",
    "        # Check that hidden dimensions match\n",
    "        assert encoder.hidden_dim == decoder.hidden_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "\n",
    "        # Check that cell types match\n",
    "        assert encoder.cell_type == decoder.cell_type, \\\n",
    "            \"Encoder and decoder must use the same cell type!\"\n",
    "\n",
    "        # Create adapter if layer counts differ\n",
    "        if encoder.n_layers != decoder.n_layers:\n",
    "            print(f\"Creating adapter from {encoder.n_layers} encoder layers to {decoder.n_layers} decoder layers\")\n",
    "            self.adapter = EncoderDecoderAdapter(\n",
    "                encoder_layers=encoder.n_layers,\n",
    "                decoder_layers=decoder.n_layers,\n",
    "                hidden_dim=encoder.hidden_dim,\n",
    "                cell_type=encoder.cell_type\n",
    "            )\n",
    "        else:\n",
    "            self.adapter = None\n",
    "\n",
    "    def forward(self, src, src_len, trg, teacher_forcing_ratio=None):\n",
    "\n",
    "        batch_size = src.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        # Tensor to store decoder outputs\n",
    "        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size).to(self.device)\n",
    "\n",
    "        # Encode source sequence\n",
    "        if self.encoder.cell_type == 'LSTM':\n",
    "            encoder_outputs, (hidden, cell) = self.encoder(src, src_len)\n",
    "\n",
    "            # Adapt encoder hidden state to decoder format if needed\n",
    "            if self.adapter is not None:\n",
    "                hidden, cell = self.adapter((hidden, cell))\n",
    "\n",
    "            # Set initial decoder state\n",
    "            decoder_hidden = (hidden, cell)\n",
    "        else:\n",
    "            encoder_outputs, hidden = self.encoder(src, src_len)\n",
    "\n",
    "            # Adapt encoder hidden state to decoder format if needed\n",
    "            if self.adapter is not None:\n",
    "                hidden = self.adapter(hidden)\n",
    "\n",
    "            # Set initial decoder state\n",
    "            decoder_hidden = hidden\n",
    "\n",
    "        # First input to the decoder is the <SOS> token\n",
    "        input = trg[:, 0]  # Shape: [batch_size]\n",
    "\n",
    "        # Use teacher forcing ratio from argument if provided, else use default\n",
    "        if teacher_forcing_ratio is None:\n",
    "            teacher_forcing_ratio = self.teacher_forcing_ratio\n",
    "\n",
    "        # Decode one step at a time\n",
    "        for t in range(1, trg_len):\n",
    "            # Pass through decoder\n",
    "            output, decoder_hidden = self.decoder(input, decoder_hidden)\n",
    "\n",
    "            # Save to outputs tensor\n",
    "            outputs[:, t, :] = output\n",
    "\n",
    "            # Decide whether to use teacher forcing\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "\n",
    "            # Get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1)\n",
    "\n",
    "            # If teacher forcing, use actual next token as next input, else use predicted token\n",
    "            input = trg[:, t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training & Evaluation (1 epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T09:31:35.357447Z",
     "iopub.status.busy": "2025-05-20T09:31:35.356672Z",
     "iopub.status.idle": "2025-05-20T09:31:35.364503Z",
     "shell.execute_reply": "2025-05-20T09:31:35.363953Z",
     "shell.execute_reply.started": "2025-05-20T09:31:35.357419Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import math\n",
    "\n",
    "def train(model, dataloader, optimizer, criterion, clip, device):\n",
    "    \n",
    "    #Training function for one epoch\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch in dataloader:\n",
    "        # Get data\n",
    "        src = batch['latin'].to(device)\n",
    "        trg = batch['devanagari'].to(device)\n",
    "        src_len = batch['latin_len'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(src, src_len, trg)\n",
    "\n",
    "        # Calculate loss\n",
    "        # output shape: [batch_size, trg_len, output_dim]\n",
    "        # trg shape: [batch_size, trg_len]\n",
    "        # Ignore the <SOS> token (first token)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[:, 1:].reshape(-1, output_dim)\n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    \n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # Get data\n",
    "            src = batch['latin'].to(device)\n",
    "            trg = batch['devanagari'].to(device)\n",
    "            src_len = batch['latin_len'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(src, src_len, trg, 0)  # Turn off teacher forcing\n",
    "\n",
    "            # Calculate loss\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[:, 1:].reshape(-1, output_dim)\n",
    "            trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T09:31:39.590134Z",
     "iopub.status.busy": "2025-05-20T09:31:39.589472Z",
     "iopub.status.idle": "2025-05-20T09:31:39.600318Z",
     "shell.execute_reply": "2025-05-20T09:31:39.599561Z",
     "shell.execute_reply.started": "2025-05-20T09:31:39.590108Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def translate_with_beam(model, src, src_len, devanagari_idx2char, device, sos_idx=1, eos_idx=2, pad_idx=0, beam_size=5, max_len=50):\n",
    "    \"\"\"\n",
    "    Translate a source sequence to target language using beam search\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    batch_size = src.shape[0]\n",
    "    translations = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Process each example in the batch separately\n",
    "        for i in range(batch_size):\n",
    "            # Get the individual source sequence\n",
    "            src_seq = src[i:i+1]  # Keep batch dimension: [1, src_len]\n",
    "            src_len_seq = src_len[i:i+1]  # [1]\n",
    "\n",
    "            # Encode the source sequence\n",
    "            if model.encoder.cell_type == 'LSTM':\n",
    "                encoder_outputs, (hidden, cell) = model.encoder(src_seq, src_len_seq)\n",
    "                \n",
    "                # Apply adapter if encoder and decoder have different layer counts\n",
    "                if model.adapter is not None:\n",
    "                    hidden, cell = model.adapter((hidden, cell))\n",
    "                \n",
    "                # Set initial decoder state\n",
    "                hidden_states = (hidden, cell)\n",
    "            else:\n",
    "                encoder_outputs, hidden = model.encoder(src_seq, src_len_seq)\n",
    "                \n",
    "                # Apply adapter if encoder and decoder have different layer counts\n",
    "                if model.adapter is not None:\n",
    "                    hidden = model.adapter(hidden)\n",
    "                    \n",
    "                # Set initial decoder state\n",
    "                hidden_states = hidden\n",
    "\n",
    "            # Initialize beam search\n",
    "            # Each beam will contain: (sequence, score, hidden_states, completed_flag)\n",
    "            beams = []\n",
    "\n",
    "            # Start with SOS token\n",
    "            beams.append(([sos_idx], 0.0, hidden_states, False))\n",
    "\n",
    "            # Generate sequence token by token\n",
    "            for t in range(max_len - 1):  # -1 because we already added SOS\n",
    "                new_beams = []\n",
    "\n",
    "                # Flag to check if all beams have completed\n",
    "                all_beams_completed = True\n",
    "\n",
    "                # Expand each current beam\n",
    "                for seq, score, states, completed in beams:\n",
    "                    if completed:\n",
    "                        # If this beam is already complete, keep it\n",
    "                        new_beams.append((seq, score, states, completed))\n",
    "                        continue\n",
    "\n",
    "                    # At least one beam is not completed\n",
    "                    all_beams_completed = False\n",
    "\n",
    "                    # Get the last token in the sequence\n",
    "                    last_token = torch.tensor([seq[-1]], device=device)\n",
    "\n",
    "                    # Forward pass through the decoder\n",
    "                    output, new_states = model.decoder(last_token, states)\n",
    "\n",
    "                    # Get probabilities\n",
    "                    probs = torch.nn.functional.log_softmax(output, dim=1)\n",
    "\n",
    "                    # Get top-k next tokens\n",
    "                    topk_probs, topk_idx = probs.topk(beam_size)\n",
    "\n",
    "                    # Create new beams\n",
    "                    for j in range(beam_size):\n",
    "                        next_token = topk_idx[0][j].item()\n",
    "                        next_score = score + topk_probs[0][j].item()\n",
    "                        next_seq = seq + [next_token]\n",
    "                        next_completed = (next_token == eos_idx)\n",
    "\n",
    "                        new_beams.append((next_seq, next_score, new_states, next_completed))\n",
    "\n",
    "                # Update beams: select top-k beams\n",
    "                # Normalize by length to avoid bias toward shorter sequences\n",
    "                beams = sorted(new_beams, key=lambda x: x[1] / len(x[0]), reverse=True)[:beam_size]\n",
    "\n",
    "                # If all beams have completed, break\n",
    "                if all_beams_completed:\n",
    "                    break\n",
    "\n",
    "            # Select the best beam\n",
    "            best_seq = beams[0][0]\n",
    "\n",
    "            # Convert to characters\n",
    "            chars = []\n",
    "            for token in best_seq:\n",
    "                if token == eos_idx:\n",
    "                    break\n",
    "                if token != sos_idx and token != pad_idx:\n",
    "                    chars.append(devanagari_idx2char[token])\n",
    "\n",
    "            translations.append(''.join(chars))\n",
    "\n",
    "    return translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T09:31:43.632712Z",
     "iopub.status.busy": "2025-05-20T09:31:43.631869Z",
     "iopub.status.idle": "2025-05-20T09:31:43.640023Z",
     "shell.execute_reply": "2025-05-20T09:31:43.639463Z",
     "shell.execute_reply.started": "2025-05-20T09:31:43.632673Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def translate(model, src, src_len, devanagari_idx2char, device, sos_idx=1, eos_idx=2, pad_idx=0, max_len=50):\n",
    "    \"\"\"\n",
    "    Translate a source sequence to target language using greedy decoding\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    batch_size = src.shape[0]\n",
    "    translations = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Encode the source sequence\n",
    "        if model.encoder.cell_type == 'LSTM':\n",
    "            encoder_outputs, (hidden, cell) = model.encoder(src, src_len)\n",
    "            \n",
    "            # Apply adapter if encoder and decoder have different layer counts\n",
    "            if model.adapter is not None:\n",
    "                hidden, cell = model.adapter((hidden, cell))\n",
    "                \n",
    "            # Set initial decoder state\n",
    "            hidden_states = (hidden, cell)\n",
    "        else:\n",
    "            encoder_outputs, hidden = model.encoder(src, src_len)\n",
    "            \n",
    "            # Apply adapter if encoder and decoder have different layer counts\n",
    "            if model.adapter is not None:\n",
    "                hidden = model.adapter(hidden)\n",
    "                \n",
    "            # Set initial decoder state\n",
    "            hidden_states = hidden\n",
    "\n",
    "        # Start with < SOS > token for each example in batch\n",
    "        input = torch.tensor([sos_idx] * batch_size, device=device)\n",
    "\n",
    "        # Initialize result sequences\n",
    "        result_sequences = torch.full((batch_size, max_len), pad_idx, dtype=torch.long, device=device)\n",
    "        result_sequences[:, 0] = input\n",
    "\n",
    "        # Track which sequences have ended\n",
    "        ended_sequences = torch.zeros(batch_size, dtype=torch.bool, device=device)\n",
    "\n",
    "        # Generate one character at a time\n",
    "        for t in range(1, max_len):\n",
    "            # Pass through decoder\n",
    "            output, hidden_states = model.decoder(input, hidden_states)\n",
    "\n",
    "            # Get the predicted token\n",
    "            pred_token = output.argmax(1)\n",
    "\n",
    "            # Save the predicted token\n",
    "            result_sequences[:, t] = pred_token\n",
    "\n",
    "            # Mark sequences that have ended (predicted <EOS>)\n",
    "            ended_sequences = ended_sequences | (pred_token == eos_idx)\n",
    "\n",
    "            # Stop if all sequences have ended\n",
    "            if ended_sequences.all():\n",
    "                break\n",
    "\n",
    "            # Next input is the predicted token\n",
    "            input = pred_token\n",
    "\n",
    "    # Convert indices to characters\n",
    "    for i in range(batch_size):\n",
    "        seq = result_sequences[i].cpu().numpy()\n",
    "        # Convert to string, stopping at <EOS> token\n",
    "        chars = []\n",
    "        for idx in seq:\n",
    "            if idx == eos_idx:\n",
    "                break\n",
    "            if idx != sos_idx and idx != pad_idx:\n",
    "                chars.append(devanagari_idx2char[idx.item()])\n",
    "\n",
    "        translations.append(''.join(chars))\n",
    "\n",
    "    return translations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T09:31:47.026759Z",
     "iopub.status.busy": "2025-05-20T09:31:47.026490Z",
     "iopub.status.idle": "2025-05-20T09:31:47.032942Z",
     "shell.execute_reply": "2025-05-20T09:31:47.032150Z",
     "shell.execute_reply.started": "2025-05-20T09:31:47.026740Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(model, dataloader, devanagari_idx2char, device, beam_size=1, sos_idx=1, eos_idx=2, pad_idx=0):\n",
    "    \n",
    "    #Calculate accuracy on a dataset using either greedy or beam search\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predictions = []\n",
    "    targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            src = batch['latin'].to(device)\n",
    "            src_len = batch['latin_len'].to(device)\n",
    "            trg_texts = batch['devanagari_text']\n",
    "\n",
    "            # Use either greedy or beam search\n",
    "            if beam_size <= 1:\n",
    "                # Use greedy search\n",
    "                translations = translate(\n",
    "                    model, src, src_len, devanagari_idx2char, device,\n",
    "                    sos_idx=sos_idx, eos_idx=eos_idx, pad_idx=pad_idx\n",
    "                )\n",
    "            else:\n",
    "                # Use beam search\n",
    "                translations = translate_with_beam(\n",
    "                    model, src, src_len, devanagari_idx2char, device,\n",
    "                    sos_idx=sos_idx, eos_idx=eos_idx, pad_idx=pad_idx,\n",
    "                    beam_size=beam_size\n",
    "                )\n",
    "\n",
    "            for pred, gold in zip(translations, trg_texts):\n",
    "                predictions.append(pred)\n",
    "                targets.append(gold)\n",
    "                if pred == gold:\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "\n",
    "    return (correct / total), predictions, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:01:04.443158Z",
     "iopub.status.busy": "2025-05-20T10:01:04.442865Z",
     "iopub.status.idle": "2025-05-20T10:01:04.456045Z",
     "shell.execute_reply": "2025-05-20T10:01:04.455474Z",
     "shell.execute_reply.started": "2025-05-20T10:01:04.443138Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "def train_model(config=None, run_name=None):\n",
    "\n",
    "    if config is not None:\n",
    "        config = wandb.config\n",
    "        wandb.run.name = run_name\n",
    "    # Otherwise, use default (Best Model)\n",
    "    elif config is None:\n",
    "        config = {\n",
    "            'emb_dim': 256,\n",
    "            'hidden_dim': 512,\n",
    "            'encoder_layers': 2,\n",
    "            'decoder_layers': 2,\n",
    "            'cell_type': 'LSTM',\n",
    "            'dropout': 0.2,\n",
    "            'lr': 0.001,\n",
    "            'batch_size': 128,\n",
    "            'epochs': 10,\n",
    "            'clip': 1.0,\n",
    "            'teacher_forcing_ratio': 0.3,\n",
    "            'beam_size': 3  # Start with greedy search (1) for stability\n",
    "        }\n",
    "\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Load data\n",
    "    data = get_dataloaders(\n",
    "        '/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.train.tsv',\n",
    "        '/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.dev.tsv',\n",
    "        '/kaggle/input/dakshina/dakshina_dataset_v1.0/hi/lexicons/hi.translit.sampled.test.tsv',\n",
    "        batch_size=config['batch_size']\n",
    "    )\n",
    "\n",
    "    train_loader = data['train_loader']\n",
    "    val_loader = data['val_loader']\n",
    "    test_loader = data['test_loader']\n",
    "\n",
    "    latin_vocab = data['latin_vocab']\n",
    "    devanagari_vocab = data['devanagari_vocab']\n",
    "    latin_idx2char = data['latin_idx2char']\n",
    "    devanagari_idx2char = data['devanagari_idx2char']\n",
    "    \n",
    "    # Get special token indices directly\n",
    "    # Extract from the dataset to ensure consistency\n",
    "    train_dataset = train_loader.dataset\n",
    "    # Use default values if the attributes don't exist\n",
    "    sos_idx = getattr(train_dataset, 'SOS_IDX', 1)\n",
    "    eos_idx = getattr(train_dataset, 'EOS_IDX', 2) \n",
    "    pad_idx = getattr(train_dataset, 'PAD_IDX', 0)\n",
    "    \n",
    "\n",
    "    # Create model\n",
    "    input_dim = len(latin_vocab)\n",
    "    output_dim = len(devanagari_vocab)\n",
    "\n",
    "    encoder = Encoder(\n",
    "        input_dim=input_dim,\n",
    "        emb_dim=config['emb_dim'],\n",
    "        hidden_dim=config['hidden_dim'],\n",
    "        n_layers=config['encoder_layers'],\n",
    "        cell_type=config['cell_type'],\n",
    "        dropout=config['dropout']\n",
    "    )\n",
    "\n",
    "    decoder = Decoder(\n",
    "        output_dim=output_dim,\n",
    "        emb_dim=config['emb_dim'],\n",
    "        hidden_dim=config['hidden_dim'],\n",
    "        n_layers=config['decoder_layers'],\n",
    "        cell_type=config['cell_type'],\n",
    "        dropout=config['dropout']\n",
    "    )\n",
    "\n",
    "    model = Seq2Seq(\n",
    "        encoder=encoder,\n",
    "        decoder=decoder,\n",
    "        device=device,\n",
    "        teacher_forcing_ratio=config['teacher_forcing_ratio']\n",
    "    )\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Calculate number of parameters\n",
    "    num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f'The model has {num_params:,} trainable parameters')\n",
    "\n",
    "    # Initialize optimizer and criterion\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['lr'])\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)  # Ignore padding index\n",
    "\n",
    "    # Training loop\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    for epoch in range(config['epochs']):\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss = train(model, train_loader, optimizer, criterion, config['clip'], device)\n",
    "        val_loss = evaluate(model, val_loader, criterion, device)\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_mins, epoch_secs = divmod(end_time - start_time, 60)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), 'best-model.pt')\n",
    "\n",
    "        print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs:.2f}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "        print(f'\\t Val. Loss: {val_loss:.3f}')\n",
    "\n",
    "        # Validation accuracy with updated function\n",
    "        val_accuracy, _, _ = calculate_accuracy(\n",
    "            model, val_loader, devanagari_idx2char, device, \n",
    "            beam_size=1,  # Use greedy search during training for speed\n",
    "            sos_idx=sos_idx, eos_idx=eos_idx, pad_idx=pad_idx\n",
    "        )\n",
    "        print(f'\\t Val. Accuracy: {val_accuracy:.3f}')\n",
    "\n",
    "        # Log to wandb\n",
    "        if wandb.run is not None:\n",
    "            wandb.log({\n",
    "                \"train_loss\": train_loss,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"val_accuracy\": val_accuracy,\n",
    "                \"epoch\": epoch\n",
    "            })\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(torch.load('best-model.pt'))\n",
    "\n",
    "    # Calculate test accuracy with beam search\n",
    "    test_accuracy, predictions, targets = calculate_accuracy(\n",
    "        model, test_loader, devanagari_idx2char, device, \n",
    "        beam_size=config['beam_size'],  # Use beam search for final evaluation\n",
    "        sos_idx=sos_idx, eos_idx=eos_idx, pad_idx=pad_idx\n",
    "    )\n",
    "    print(f'Test Accuracy (beam size={config[\"beam_size\"]}): {test_accuracy:.3f}')\n",
    "\n",
    "    # if wandb.run is not None:\n",
    "    #     wandb.log({\"test_accuracy\": test_accuracy})\n",
    "\n",
    "    #Save predictions for analysis\n",
    "    latin_texts = []\n",
    "    devanagari_texts = []\n",
    "\n",
    "    for batch in test_loader:\n",
    "        latin_texts.extend(batch['latin_text'])\n",
    "        devanagari_texts.extend(batch['devanagari_text'])\n",
    "\n",
    "    # Create DataFrame with all 4 columns\n",
    "    results = pd.DataFrame({\n",
    "        'latin': latin_texts[:len(predictions)],\n",
    "        'true': devanagari_texts[:len(predictions)],\n",
    "        'predicted': predictions,\n",
    "        'accuracy': [1 if pred == target else 0 for pred, target in zip(predictions, devanagari_texts[:len(predictions)])]\n",
    "    })\n",
    "\n",
    "    \n",
    "    results.to_csv('./test_vanilla.csv', index=False)\n",
    "    \n",
    "\n",
    "    return model  #, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sweep Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T05:33:32.879603Z",
     "iopub.status.busy": "2025-05-20T05:33:32.879083Z",
     "iopub.status.idle": "2025-05-20T05:33:32.887522Z",
     "shell.execute_reply": "2025-05-20T05:33:32.886853Z",
     "shell.execute_reply.started": "2025-05-20T05:33:32.879581Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "        'method': 'bayes',  # Bayesian optimization\n",
    "        'metric': {\n",
    "            'name': 'val_accuracy',\n",
    "            'goal': 'maximize'\n",
    "        },\n",
    "        'parameters': {\n",
    "            'emb_dim': {\n",
    "                'values': [16, 32, 64, 128, 256]\n",
    "            },\n",
    "            'hidden_dim': {\n",
    "                'values': [32, 64, 128, 256, 512]\n",
    "            },\n",
    "            'encoder_layers': {\n",
    "                'values': [1, 2, 3]\n",
    "            },\n",
    "            'decoder_layers': {\n",
    "                'values': [1, 2, 3]\n",
    "            },\n",
    "            'cell_type': {\n",
    "                'values': ['RNN', 'GRU', 'LSTM']\n",
    "            },\n",
    "            'dropout': {\n",
    "                'values': [0.1, 0.2, 0.3,]\n",
    "            },\n",
    "            'lr': {\n",
    "                'values': [0.0001, 0.001, 0.01]\n",
    "            },\n",
    "            'batch_size': {\n",
    "                'values': [32, 64, 128]\n",
    "            },\n",
    "            'clip': {\n",
    "                'values': [0.1, 1.0, 5.0]\n",
    "            },\n",
    "            'teacher_forcing_ratio': {\n",
    "                'values': [0.3, 0.5, 0.7]\n",
    "            },\n",
    "            'beam_size': {\n",
    "                'values': [1, 3, 5]  # 1 is equivalent to greedy search\n",
    "            },\n",
    "            'epochs': {\n",
    "                'values': [2]\n",
    "            }\n",
    "        }\n",
    "}\n",
    "\n",
    "def run_sweep():\n",
    "        run = wandb.init()\n",
    "        config = wandb.config\n",
    "        run_name = (\n",
    "        f\"{config.cell_type}_\"\n",
    "        f\"enc_{config.encoder_layers}_dec_{config.decoder_layers}_\"\n",
    "        f\"hdim_{config.hidden_dim}_\"\n",
    "        f\"emb_{config.emb_dim}_\"\n",
    "        f\"bs_{config.batch_size}_\"\n",
    "        f\"drop_{config.dropout}_\"\n",
    "        f\"beam_{config.beam_size}_\"\n",
    "        f\"lr_{config.lr}_\"\n",
    "        f\"clip_{config.clip}_\"\n",
    "        f\"tf_{config.teacher_forcing_ratio}_\"\n",
    "        f\"epoch_{config.epochs}\"\n",
    "        )\n",
    "        train_model(config=wandb.config, run_name=run_name)  # wandb.config is automatically passed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T10:01:10.667343Z",
     "iopub.status.busy": "2025-05-20T10:01:10.667088Z",
     "iopub.status.idle": "2025-05-20T10:05:14.715342Z",
     "shell.execute_reply": "2025-05-20T10:05:14.714792Z",
     "shell.execute_reply.started": "2025-05-20T10:01:10.667324Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "The model has 7,414,594 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 17.83s\n",
      "\tTrain Loss: 1.703\n",
      "\t Val. Loss: 1.132\n",
      "\t Val. Accuracy: 0.207\n",
      "Epoch: 02 | Time: 0.0m 17.92s\n",
      "\tTrain Loss: 0.831\n",
      "\t Val. Loss: 0.964\n",
      "\t Val. Accuracy: 0.304\n",
      "Epoch: 03 | Time: 0.0m 17.88s\n",
      "\tTrain Loss: 0.632\n",
      "\t Val. Loss: 0.913\n",
      "\t Val. Accuracy: 0.345\n",
      "Epoch: 04 | Time: 0.0m 18.00s\n",
      "\tTrain Loss: 0.498\n",
      "\t Val. Loss: 0.935\n",
      "\t Val. Accuracy: 0.351\n",
      "Epoch: 05 | Time: 0.0m 18.01s\n",
      "\tTrain Loss: 0.411\n",
      "\t Val. Loss: 0.948\n",
      "\t Val. Accuracy: 0.353\n",
      "Epoch: 06 | Time: 0.0m 17.98s\n",
      "\tTrain Loss: 0.342\n",
      "\t Val. Loss: 0.935\n",
      "\t Val. Accuracy: 0.374\n",
      "Epoch: 07 | Time: 0.0m 18.17s\n",
      "\tTrain Loss: 0.283\n",
      "\t Val. Loss: 0.996\n",
      "\t Val. Accuracy: 0.380\n",
      "Epoch: 08 | Time: 0.0m 18.05s\n",
      "\tTrain Loss: 0.238\n",
      "\t Val. Loss: 1.036\n",
      "\t Val. Accuracy: 0.374\n",
      "Epoch: 09 | Time: 0.0m 18.23s\n",
      "\tTrain Loss: 0.203\n",
      "\t Val. Loss: 1.084\n",
      "\t Val. Accuracy: 0.370\n",
      "Epoch: 10 | Time: 0.0m 18.10s\n",
      "\tTrain Loss: 0.183\n",
      "\t Val. Loss: 1.113\n",
      "\t Val. Accuracy: 0.370\n",
      "Test Accuracy (beam size=3): 0.358\n"
     ]
    }
   ],
   "source": [
    "model=train_model(config=None, run_name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wandb Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T05:39:37.806975Z",
     "iopub.status.busy": "2025-05-20T05:39:37.806374Z",
     "iopub.status.idle": "2025-05-20T08:08:44.581094Z",
     "shell.execute_reply": "2025-05-20T08:08:44.580377Z",
     "shell.execute_reply.started": "2025-05-20T05:39:37.806952Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: r9ulhvpq\n",
      "Sweep URL: https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5eem3lkq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_053944-5eem3lkq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/5eem3lkq' target=\"_blank\">vague-sweep-1</a></strong> to <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/5eem3lkq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/5eem3lkq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Creating adapter from 2 encoder layers to 3 decoder layers\n",
      "The model has 12,664,642 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 21.17s\n",
      "\tTrain Loss: 2.009\n",
      "\t Val. Loss: 1.261\n",
      "\t Val. Accuracy: 0.137\n",
      "Epoch: 02 | Time: 0.0m 21.03s\n",
      "\tTrain Loss: 0.977\n",
      "\t Val. Loss: 1.013\n",
      "\t Val. Accuracy: 0.265\n",
      "Epoch: 03 | Time: 0.0m 21.12s\n",
      "\tTrain Loss: 0.733\n",
      "\t Val. Loss: 0.937\n",
      "\t Val. Accuracy: 0.327\n",
      "Epoch: 04 | Time: 0.0m 20.92s\n",
      "\tTrain Loss: 0.585\n",
      "\t Val. Loss: 0.944\n",
      "\t Val. Accuracy: 0.333\n",
      "Epoch: 05 | Time: 0.0m 20.82s\n",
      "\tTrain Loss: 0.478\n",
      "\t Val. Loss: 0.946\n",
      "\t Val. Accuracy: 0.354\n",
      "Epoch: 06 | Time: 0.0m 21.12s\n",
      "\tTrain Loss: 0.392\n",
      "\t Val. Loss: 0.958\n",
      "\t Val. Accuracy: 0.347\n",
      "Epoch: 07 | Time: 0.0m 21.14s\n",
      "\tTrain Loss: 0.323\n",
      "\t Val. Loss: 1.000\n",
      "\t Val. Accuracy: 0.362\n",
      "Epoch: 08 | Time: 0.0m 20.99s\n",
      "\tTrain Loss: 0.273\n",
      "\t Val. Loss: 1.061\n",
      "\t Val. Accuracy: 0.355\n",
      "Epoch: 09 | Time: 0.0m 20.88s\n",
      "\tTrain Loss: 0.236\n",
      "\t Val. Loss: 1.073\n",
      "\t Val. Accuracy: 0.369\n",
      "Epoch: 10 | Time: 0.0m 20.94s\n",
      "\tTrain Loss: 0.207\n",
      "\t Val. Loss: 1.105\n",
      "\t Val. Accuracy: 0.364\n",
      "Epoch: 11 | Time: 0.0m 21.02s\n",
      "\tTrain Loss: 0.188\n",
      "\t Val. Loss: 1.175\n",
      "\t Val. Accuracy: 0.347\n",
      "Epoch: 12 | Time: 0.0m 20.86s\n",
      "\tTrain Loss: 0.170\n",
      "\t Val. Loss: 1.193\n",
      "\t Val. Accuracy: 0.349\n",
      "Epoch: 13 | Time: 0.0m 20.99s\n",
      "\tTrain Loss: 0.161\n",
      "\t Val. Loss: 1.197\n",
      "\t Val. Accuracy: 0.364\n",
      "Epoch: 14 | Time: 0.0m 20.91s\n",
      "\tTrain Loss: 0.152\n",
      "\t Val. Loss: 1.266\n",
      "\t Val. Accuracy: 0.355\n",
      "Epoch: 15 | Time: 0.0m 20.82s\n",
      "\tTrain Loss: 0.148\n",
      "\t Val. Loss: 1.259\n",
      "\t Val. Accuracy: 0.349\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>0.14834</td></tr><tr><td>val_accuracy</td><td>0.34901</td></tr><tr><td>val_loss</td><td>1.25853</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LSTM_enc_2_dec_3_hdim_512_emb_256_bs_128_drop_0.3_beam_1_lr_0.001_clip_5_tf_0.3_epoch_15</strong> at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/5eem3lkq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/5eem3lkq</a><br> View project at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_053944-5eem3lkq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: j012sth9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_054531-j012sth9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/j012sth9' target=\"_blank\">sparkling-sweep-2</a></strong> to <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/j012sth9' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/j012sth9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Creating adapter from 3 encoder layers to 2 decoder layers\n",
      "The model has 8,725,314 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 28.22s\n",
      "\tTrain Loss: 2.310\n",
      "\t Val. Loss: 1.660\n",
      "\t Val. Accuracy: 0.044\n",
      "Epoch: 02 | Time: 0.0m 27.83s\n",
      "\tTrain Loss: 1.430\n",
      "\t Val. Loss: 1.325\n",
      "\t Val. Accuracy: 0.128\n",
      "Epoch: 03 | Time: 0.0m 28.23s\n",
      "\tTrain Loss: 1.155\n",
      "\t Val. Loss: 1.184\n",
      "\t Val. Accuracy: 0.186\n",
      "Epoch: 04 | Time: 0.0m 28.11s\n",
      "\tTrain Loss: 1.002\n",
      "\t Val. Loss: 1.113\n",
      "\t Val. Accuracy: 0.238\n",
      "Epoch: 05 | Time: 0.0m 27.89s\n",
      "\tTrain Loss: 0.897\n",
      "\t Val. Loss: 1.030\n",
      "\t Val. Accuracy: 0.252\n",
      "Epoch: 06 | Time: 0.0m 27.85s\n",
      "\tTrain Loss: 0.814\n",
      "\t Val. Loss: 1.020\n",
      "\t Val. Accuracy: 0.277\n",
      "Epoch: 07 | Time: 0.0m 27.86s\n",
      "\tTrain Loss: 0.741\n",
      "\t Val. Loss: 0.975\n",
      "\t Val. Accuracy: 0.314\n",
      "Epoch: 08 | Time: 0.0m 27.98s\n",
      "\tTrain Loss: 0.687\n",
      "\t Val. Loss: 0.980\n",
      "\t Val. Accuracy: 0.311\n",
      "Epoch: 09 | Time: 0.0m 27.95s\n",
      "\tTrain Loss: 0.639\n",
      "\t Val. Loss: 0.975\n",
      "\t Val. Accuracy: 0.330\n",
      "Epoch: 10 | Time: 0.0m 28.10s\n",
      "\tTrain Loss: 0.598\n",
      "\t Val. Loss: 0.968\n",
      "\t Val. Accuracy: 0.331\n",
      "Epoch: 11 | Time: 0.0m 27.79s\n",
      "\tTrain Loss: 0.547\n",
      "\t Val. Loss: 0.985\n",
      "\t Val. Accuracy: 0.338\n",
      "Epoch: 12 | Time: 0.0m 28.14s\n",
      "\tTrain Loss: 0.512\n",
      "\t Val. Loss: 0.988\n",
      "\t Val. Accuracy: 0.340\n",
      "Epoch: 13 | Time: 0.0m 27.87s\n",
      "\tTrain Loss: 0.481\n",
      "\t Val. Loss: 0.973\n",
      "\t Val. Accuracy: 0.356\n",
      "Epoch: 14 | Time: 0.0m 27.95s\n",
      "\tTrain Loss: 0.445\n",
      "\t Val. Loss: 0.975\n",
      "\t Val. Accuracy: 0.353\n",
      "Epoch: 15 | Time: 0.0m 27.96s\n",
      "\tTrain Loss: 0.412\n",
      "\t Val. Loss: 0.995\n",
      "\t Val. Accuracy: 0.355\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>0.4123</td></tr><tr><td>val_accuracy</td><td>0.35521</td></tr><tr><td>val_loss</td><td>0.99511</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GRU_enc_3_dec_2_hdim_512_emb_256_bs_64_drop_0.3_beam_3_lr_0.0001_clip_1_tf_0.3_epoch_15</strong> at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/j012sth9' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/j012sth9</a><br> View project at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_054531-j012sth9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: x2tc3279 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_055305-x2tc3279</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/x2tc3279' target=\"_blank\">prime-sweep-3</a></strong> to <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/x2tc3279' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/x2tc3279</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Creating adapter from 3 encoder layers to 2 decoder layers\n",
      "The model has 12,663,618 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 20.54s\n",
      "\tTrain Loss: 2.830\n",
      "\t Val. Loss: 2.214\n",
      "\t Val. Accuracy: 0.003\n",
      "Epoch: 02 | Time: 0.0m 20.59s\n",
      "\tTrain Loss: 1.881\n",
      "\t Val. Loss: 1.665\n",
      "\t Val. Accuracy: 0.050\n",
      "Epoch: 03 | Time: 0.0m 20.47s\n",
      "\tTrain Loss: 1.479\n",
      "\t Val. Loss: 1.418\n",
      "\t Val. Accuracy: 0.098\n",
      "Epoch: 04 | Time: 0.0m 20.56s\n",
      "\tTrain Loss: 1.257\n",
      "\t Val. Loss: 1.273\n",
      "\t Val. Accuracy: 0.150\n",
      "Epoch: 05 | Time: 0.0m 20.40s\n",
      "\tTrain Loss: 1.109\n",
      "\t Val. Loss: 1.194\n",
      "\t Val. Accuracy: 0.179\n",
      "Epoch: 06 | Time: 0.0m 20.32s\n",
      "\tTrain Loss: 0.998\n",
      "\t Val. Loss: 1.123\n",
      "\t Val. Accuracy: 0.221\n",
      "Epoch: 07 | Time: 0.0m 20.62s\n",
      "\tTrain Loss: 0.912\n",
      "\t Val. Loss: 1.081\n",
      "\t Val. Accuracy: 0.247\n",
      "Epoch: 08 | Time: 0.0m 20.52s\n",
      "\tTrain Loss: 0.849\n",
      "\t Val. Loss: 1.043\n",
      "\t Val. Accuracy: 0.270\n",
      "Epoch: 09 | Time: 0.0m 20.35s\n",
      "\tTrain Loss: 0.781\n",
      "\t Val. Loss: 1.017\n",
      "\t Val. Accuracy: 0.291\n",
      "Epoch: 10 | Time: 0.0m 20.58s\n",
      "\tTrain Loss: 0.731\n",
      "\t Val. Loss: 0.996\n",
      "\t Val. Accuracy: 0.299\n",
      "Epoch: 11 | Time: 0.0m 20.40s\n",
      "\tTrain Loss: 0.679\n",
      "\t Val. Loss: 0.967\n",
      "\t Val. Accuracy: 0.313\n",
      "Epoch: 12 | Time: 0.0m 20.44s\n",
      "\tTrain Loss: 0.630\n",
      "\t Val. Loss: 0.962\n",
      "\t Val. Accuracy: 0.312\n",
      "Epoch: 13 | Time: 0.0m 20.55s\n",
      "\tTrain Loss: 0.592\n",
      "\t Val. Loss: 0.971\n",
      "\t Val. Accuracy: 0.321\n",
      "Epoch: 14 | Time: 0.0m 20.58s\n",
      "\tTrain Loss: 0.556\n",
      "\t Val. Loss: 0.967\n",
      "\t Val. Accuracy: 0.326\n",
      "Epoch: 15 | Time: 0.0m 20.36s\n",
      "\tTrain Loss: 0.529\n",
      "\t Val. Loss: 0.952\n",
      "\t Val. Accuracy: 0.333\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>0.52935</td></tr><tr><td>val_accuracy</td><td>0.33341</td></tr><tr><td>val_loss</td><td>0.95237</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LSTM_enc_3_dec_2_hdim_512_emb_256_bs_128_drop_0.2_beam_3_lr_0.0001_clip_5_tf_0.3_epoch_15</strong> at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/x2tc3279' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/x2tc3279</a><br> View project at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_055305-x2tc3279/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bhytsej2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_055842-bhytsej2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/bhytsej2' target=\"_blank\">elated-sweep-4</a></strong> to <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/bhytsej2' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/bhytsej2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Creating adapter from 2 encoder layers to 3 decoder layers\n",
      "The model has 12,664,642 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 21.05s\n",
      "\tTrain Loss: 2.540\n",
      "\t Val. Loss: 2.226\n",
      "\t Val. Accuracy: 0.011\n",
      "Epoch: 02 | Time: 0.0m 21.00s\n",
      "\tTrain Loss: 1.842\n",
      "\t Val. Loss: 1.833\n",
      "\t Val. Accuracy: 0.036\n",
      "Epoch: 03 | Time: 0.0m 21.04s\n",
      "\tTrain Loss: 1.607\n",
      "\t Val. Loss: 1.739\n",
      "\t Val. Accuracy: 0.066\n",
      "Epoch: 04 | Time: 0.0m 21.18s\n",
      "\tTrain Loss: 1.492\n",
      "\t Val. Loss: 1.696\n",
      "\t Val. Accuracy: 0.067\n",
      "Epoch: 05 | Time: 0.0m 20.90s\n",
      "\tTrain Loss: 1.389\n",
      "\t Val. Loss: 1.636\n",
      "\t Val. Accuracy: 0.092\n",
      "Epoch: 06 | Time: 0.0m 21.17s\n",
      "\tTrain Loss: 1.341\n",
      "\t Val. Loss: 1.613\n",
      "\t Val. Accuracy: 0.111\n",
      "Epoch: 07 | Time: 0.0m 20.99s\n",
      "\tTrain Loss: 1.293\n",
      "\t Val. Loss: 1.620\n",
      "\t Val. Accuracy: 0.110\n",
      "Epoch: 08 | Time: 0.0m 20.96s\n",
      "\tTrain Loss: 1.254\n",
      "\t Val. Loss: 1.566\n",
      "\t Val. Accuracy: 0.106\n",
      "Epoch: 09 | Time: 0.0m 20.93s\n",
      "\tTrain Loss: 1.225\n",
      "\t Val. Loss: 1.544\n",
      "\t Val. Accuracy: 0.121\n",
      "Epoch: 10 | Time: 0.0m 21.09s\n",
      "\tTrain Loss: 1.173\n",
      "\t Val. Loss: 1.538\n",
      "\t Val. Accuracy: 0.120\n",
      "Epoch: 11 | Time: 0.0m 21.02s\n",
      "\tTrain Loss: 1.146\n",
      "\t Val. Loss: 1.512\n",
      "\t Val. Accuracy: 0.132\n",
      "Epoch: 12 | Time: 0.0m 20.91s\n",
      "\tTrain Loss: 1.134\n",
      "\t Val. Loss: 1.532\n",
      "\t Val. Accuracy: 0.125\n",
      "Epoch: 13 | Time: 0.0m 21.04s\n",
      "\tTrain Loss: 1.110\n",
      "\t Val. Loss: 1.564\n",
      "\t Val. Accuracy: 0.128\n",
      "Epoch: 14 | Time: 0.0m 21.04s\n",
      "\tTrain Loss: 1.088\n",
      "\t Val. Loss: 1.497\n",
      "\t Val. Accuracy: 0.134\n",
      "Epoch: 15 | Time: 0.0m 20.85s\n",
      "\tTrain Loss: 1.031\n",
      "\t Val. Loss: 1.549\n",
      "\t Val. Accuracy: 0.143\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>1.03084</td></tr><tr><td>val_accuracy</td><td>0.14273</td></tr><tr><td>val_loss</td><td>1.54917</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LSTM_enc_2_dec_3_hdim_512_emb_256_bs_128_drop_0.3_beam_3_lr_0.01_clip_5_tf_0.5_epoch_15</strong> at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/bhytsej2' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/bhytsej2</a><br> View project at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_055842-bhytsej2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fvbubt5w with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_060426-fvbubt5w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/fvbubt5w' target=\"_blank\">kind-sweep-5</a></strong> to <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/fvbubt5w' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/fvbubt5w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Creating adapter from 3 encoder layers to 2 decoder layers\n",
      "The model has 2,408,770 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 25.60s\n",
      "\tTrain Loss: 2.144\n",
      "\t Val. Loss: 2.031\n",
      "\t Val. Accuracy: 0.024\n",
      "Epoch: 02 | Time: 0.0m 25.72s\n",
      "\tTrain Loss: 2.027\n",
      "\t Val. Loss: 2.117\n",
      "\t Val. Accuracy: 0.013\n",
      "Epoch: 03 | Time: 0.0m 25.35s\n",
      "\tTrain Loss: 1.941\n",
      "\t Val. Loss: 2.157\n",
      "\t Val. Accuracy: 0.008\n",
      "Epoch: 04 | Time: 0.0m 25.49s\n",
      "\tTrain Loss: 1.899\n",
      "\t Val. Loss: 2.021\n",
      "\t Val. Accuracy: 0.021\n",
      "Epoch: 05 | Time: 0.0m 25.59s\n",
      "\tTrain Loss: 1.850\n",
      "\t Val. Loss: 2.102\n",
      "\t Val. Accuracy: 0.008\n",
      "Epoch: 06 | Time: 0.0m 25.62s\n",
      "\tTrain Loss: 1.954\n",
      "\t Val. Loss: 2.032\n",
      "\t Val. Accuracy: 0.011\n",
      "Epoch: 07 | Time: 0.0m 25.91s\n",
      "\tTrain Loss: 1.919\n",
      "\t Val. Loss: 1.914\n",
      "\t Val. Accuracy: 0.024\n",
      "Epoch: 08 | Time: 0.0m 25.79s\n",
      "\tTrain Loss: 1.867\n",
      "\t Val. Loss: 1.839\n",
      "\t Val. Accuracy: 0.028\n",
      "Epoch: 09 | Time: 0.0m 25.41s\n",
      "\tTrain Loss: 1.770\n",
      "\t Val. Loss: 1.903\n",
      "\t Val. Accuracy: 0.029\n",
      "Epoch: 10 | Time: 0.0m 25.54s\n",
      "\tTrain Loss: 1.766\n",
      "\t Val. Loss: 1.850\n",
      "\t Val. Accuracy: 0.030\n",
      "Epoch: 11 | Time: 0.0m 25.49s\n",
      "\tTrain Loss: 1.768\n",
      "\t Val. Loss: 1.994\n",
      "\t Val. Accuracy: 0.013\n",
      "Epoch: 12 | Time: 0.0m 25.39s\n",
      "\tTrain Loss: 1.879\n",
      "\t Val. Loss: 1.941\n",
      "\t Val. Accuracy: 0.025\n",
      "Epoch: 13 | Time: 0.0m 25.53s\n",
      "\tTrain Loss: 1.806\n",
      "\t Val. Loss: 1.853\n",
      "\t Val. Accuracy: 0.013\n",
      "Epoch: 14 | Time: 0.0m 25.57s\n",
      "\tTrain Loss: 1.783\n",
      "\t Val. Loss: 1.903\n",
      "\t Val. Accuracy: 0.023\n",
      "Epoch: 15 | Time: 0.0m 25.75s\n",
      "\tTrain Loss: 1.754\n",
      "\t Val. Loss: 2.017\n",
      "\t Val. Accuracy: 0.013\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>1.75421</td></tr><tr><td>val_accuracy</td><td>0.01308</td></tr><tr><td>val_loss</td><td>2.01657</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GRU_enc_3_dec_2_hdim_256_emb_256_bs_64_drop_0.2_beam_3_lr_0.01_clip_1_tf_0.5_epoch_15</strong> at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/fvbubt5w' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/fvbubt5w</a><br> View project at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_060426-fvbubt5w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3r1wuoud with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_061140-3r1wuoud</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/3r1wuoud' target=\"_blank\">still-sweep-6</a></strong> to <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/3r1wuoud' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/3r1wuoud</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Creating adapter from 1 encoder layers to 3 decoder layers\n",
      "The model has 2,541,378 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 29.35s\n",
      "\tTrain Loss: 1.852\n",
      "\t Val. Loss: 1.511\n",
      "\t Val. Accuracy: 0.156\n",
      "Epoch: 02 | Time: 0.0m 28.88s\n",
      "\tTrain Loss: 0.907\n",
      "\t Val. Loss: 1.305\n",
      "\t Val. Accuracy: 0.269\n",
      "Epoch: 03 | Time: 0.0m 28.97s\n",
      "\tTrain Loss: 0.695\n",
      "\t Val. Loss: 1.249\n",
      "\t Val. Accuracy: 0.293\n",
      "Epoch: 04 | Time: 0.0m 29.25s\n",
      "\tTrain Loss: 0.598\n",
      "\t Val. Loss: 1.228\n",
      "\t Val. Accuracy: 0.320\n",
      "Epoch: 05 | Time: 0.0m 29.07s\n",
      "\tTrain Loss: 0.520\n",
      "\t Val. Loss: 1.227\n",
      "\t Val. Accuracy: 0.333\n",
      "Epoch: 06 | Time: 0.0m 29.26s\n",
      "\tTrain Loss: 0.464\n",
      "\t Val. Loss: 1.212\n",
      "\t Val. Accuracy: 0.349\n",
      "Epoch: 07 | Time: 0.0m 28.88s\n",
      "\tTrain Loss: 0.418\n",
      "\t Val. Loss: 1.239\n",
      "\t Val. Accuracy: 0.350\n",
      "Epoch: 08 | Time: 0.0m 29.13s\n",
      "\tTrain Loss: 0.372\n",
      "\t Val. Loss: 1.269\n",
      "\t Val. Accuracy: 0.350\n",
      "Epoch: 09 | Time: 0.0m 29.37s\n",
      "\tTrain Loss: 0.343\n",
      "\t Val. Loss: 1.268\n",
      "\t Val. Accuracy: 0.351\n",
      "Epoch: 10 | Time: 0.0m 29.08s\n",
      "\tTrain Loss: 0.309\n",
      "\t Val. Loss: 1.327\n",
      "\t Val. Accuracy: 0.343\n",
      "Epoch: 11 | Time: 0.0m 29.11s\n",
      "\tTrain Loss: 0.285\n",
      "\t Val. Loss: 1.327\n",
      "\t Val. Accuracy: 0.358\n",
      "Epoch: 12 | Time: 0.0m 29.19s\n",
      "\tTrain Loss: 0.269\n",
      "\t Val. Loss: 1.366\n",
      "\t Val. Accuracy: 0.347\n",
      "Epoch: 13 | Time: 0.0m 29.15s\n",
      "\tTrain Loss: 0.247\n",
      "\t Val. Loss: 1.445\n",
      "\t Val. Accuracy: 0.343\n",
      "Epoch: 14 | Time: 0.0m 29.03s\n",
      "\tTrain Loss: 0.228\n",
      "\t Val. Loss: 1.429\n",
      "\t Val. Accuracy: 0.347\n",
      "Epoch: 15 | Time: 0.0m 28.94s\n",
      "\tTrain Loss: 0.217\n",
      "\t Val. Loss: 1.434\n",
      "\t Val. Accuracy: 0.335\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>0.21693</td></tr><tr><td>val_accuracy</td><td>0.33479</td></tr><tr><td>val_loss</td><td>1.43372</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LSTM_enc_1_dec_3_hdim_256_emb_256_bs_64_drop_0.2_beam_1_lr_0.001_clip_1_tf_0.7_epoch_15</strong> at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/3r1wuoud' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/3r1wuoud</a><br> View project at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_061140-3r1wuoud/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 020hx6zp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_061929-020hx6zp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/020hx6zp' target=\"_blank\">dauntless-sweep-7</a></strong> to <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/020hx6zp' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/020hx6zp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "The model has 2,409,794 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 47.05s\n",
      "\tTrain Loss: 1.933\n",
      "\t Val. Loss: 1.678\n",
      "\t Val. Accuracy: 0.035\n",
      "Epoch: 02 | Time: 0.0m 46.74s\n",
      "\tTrain Loss: 1.695\n",
      "\t Val. Loss: 1.650\n",
      "\t Val. Accuracy: 0.046\n",
      "Epoch: 03 | Time: 0.0m 46.99s\n",
      "\tTrain Loss: 1.676\n",
      "\t Val. Loss: 1.659\n",
      "\t Val. Accuracy: 0.046\n",
      "Epoch: 04 | Time: 0.0m 47.03s\n",
      "\tTrain Loss: 1.672\n",
      "\t Val. Loss: 1.679\n",
      "\t Val. Accuracy: 0.045\n",
      "Epoch: 05 | Time: 0.0m 47.00s\n",
      "\tTrain Loss: 1.699\n",
      "\t Val. Loss: 1.631\n",
      "\t Val. Accuracy: 0.049\n",
      "Epoch: 06 | Time: 0.0m 46.99s\n",
      "\tTrain Loss: 1.725\n",
      "\t Val. Loss: 1.696\n",
      "\t Val. Accuracy: 0.040\n",
      "Epoch: 07 | Time: 0.0m 46.87s\n",
      "\tTrain Loss: 1.738\n",
      "\t Val. Loss: 1.696\n",
      "\t Val. Accuracy: 0.042\n",
      "Epoch: 08 | Time: 0.0m 46.98s\n",
      "\tTrain Loss: 1.768\n",
      "\t Val. Loss: 1.733\n",
      "\t Val. Accuracy: 0.031\n",
      "Epoch: 09 | Time: 0.0m 46.89s\n",
      "\tTrain Loss: 1.782\n",
      "\t Val. Loss: 1.736\n",
      "\t Val. Accuracy: 0.021\n",
      "Epoch: 10 | Time: 0.0m 47.31s\n",
      "\tTrain Loss: 1.828\n",
      "\t Val. Loss: 1.781\n",
      "\t Val. Accuracy: 0.028\n",
      "Epoch: 11 | Time: 0.0m 47.11s\n",
      "\tTrain Loss: 1.862\n",
      "\t Val. Loss: 1.768\n",
      "\t Val. Accuracy: 0.024\n",
      "Epoch: 12 | Time: 0.0m 46.80s\n",
      "\tTrain Loss: 1.865\n",
      "\t Val. Loss: 1.888\n",
      "\t Val. Accuracy: 0.026\n",
      "Epoch: 13 | Time: 0.0m 46.92s\n",
      "\tTrain Loss: 1.954\n",
      "\t Val. Loss: 1.937\n",
      "\t Val. Accuracy: 0.012\n",
      "Epoch: 14 | Time: 0.0m 46.93s\n",
      "\tTrain Loss: 1.948\n",
      "\t Val. Loss: 1.780\n",
      "\t Val. Accuracy: 0.027\n",
      "Epoch: 15 | Time: 0.0m 47.48s\n",
      "\tTrain Loss: 1.927\n",
      "\t Val. Loss: 1.771\n",
      "\t Val. Accuracy: 0.028\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>1.92694</td></tr><tr><td>val_accuracy</td><td>0.02822</td></tr><tr><td>val_loss</td><td>1.77143</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GRU_enc_3_dec_3_hdim_256_emb_256_bs_32_drop_0.2_beam_5_lr_0.01_clip_0.1_tf_0.3_epoch_15</strong> at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/020hx6zp' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/020hx6zp</a><br> View project at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_061929-020hx6zp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zfa7thum with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_063204-zfa7thum</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/zfa7thum' target=\"_blank\">balmy-sweep-8</a></strong> to <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/zfa7thum' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/zfa7thum</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Creating adapter from 2 encoder layers to 3 decoder layers\n",
      "The model has 12,664,642 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 21.20s\n",
      "\tTrain Loss: 2.833\n",
      "\t Val. Loss: 2.207\n",
      "\t Val. Accuracy: 0.003\n",
      "Epoch: 02 | Time: 0.0m 21.02s\n",
      "\tTrain Loss: 1.941\n",
      "\t Val. Loss: 1.690\n",
      "\t Val. Accuracy: 0.029\n",
      "Epoch: 03 | Time: 0.0m 20.87s\n",
      "\tTrain Loss: 1.565\n",
      "\t Val. Loss: 1.450\n",
      "\t Val. Accuracy: 0.072\n",
      "Epoch: 04 | Time: 0.0m 21.14s\n",
      "\tTrain Loss: 1.328\n",
      "\t Val. Loss: 1.314\n",
      "\t Val. Accuracy: 0.118\n",
      "Epoch: 05 | Time: 0.0m 21.14s\n",
      "\tTrain Loss: 1.181\n",
      "\t Val. Loss: 1.221\n",
      "\t Val. Accuracy: 0.161\n",
      "Epoch: 06 | Time: 0.0m 20.97s\n",
      "\tTrain Loss: 1.064\n",
      "\t Val. Loss: 1.153\n",
      "\t Val. Accuracy: 0.205\n",
      "Epoch: 07 | Time: 0.0m 20.92s\n",
      "\tTrain Loss: 0.987\n",
      "\t Val. Loss: 1.122\n",
      "\t Val. Accuracy: 0.223\n",
      "Epoch: 08 | Time: 0.0m 20.94s\n",
      "\tTrain Loss: 0.910\n",
      "\t Val. Loss: 1.064\n",
      "\t Val. Accuracy: 0.250\n",
      "Epoch: 09 | Time: 0.0m 21.17s\n",
      "\tTrain Loss: 0.853\n",
      "\t Val. Loss: 1.043\n",
      "\t Val. Accuracy: 0.258\n",
      "Epoch: 10 | Time: 0.0m 20.94s\n",
      "\tTrain Loss: 0.794\n",
      "\t Val. Loss: 1.031\n",
      "\t Val. Accuracy: 0.264\n",
      "Epoch: 11 | Time: 0.0m 21.01s\n",
      "\tTrain Loss: 0.750\n",
      "\t Val. Loss: 1.001\n",
      "\t Val. Accuracy: 0.282\n",
      "Epoch: 12 | Time: 0.0m 21.07s\n",
      "\tTrain Loss: 0.707\n",
      "\t Val. Loss: 0.989\n",
      "\t Val. Accuracy: 0.298\n",
      "Epoch: 13 | Time: 0.0m 20.97s\n",
      "\tTrain Loss: 0.662\n",
      "\t Val. Loss: 0.990\n",
      "\t Val. Accuracy: 0.306\n",
      "Epoch: 14 | Time: 0.0m 20.92s\n",
      "\tTrain Loss: 0.629\n",
      "\t Val. Loss: 0.979\n",
      "\t Val. Accuracy: 0.311\n",
      "Epoch: 15 | Time: 0.0m 21.00s\n",
      "\tTrain Loss: 0.589\n",
      "\t Val. Loss: 0.968\n",
      "\t Val. Accuracy: 0.320\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>0.58868</td></tr><tr><td>val_accuracy</td><td>0.3201</td></tr><tr><td>val_loss</td><td>0.96767</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LSTM_enc_2_dec_3_hdim_512_emb_256_bs_128_drop_0.3_beam_1_lr_0.0001_clip_5_tf_0.3_epoch_15</strong> at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/zfa7thum' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/zfa7thum</a><br> View project at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_063204-zfa7thum/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1dwams57 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_063752-1dwams57</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/1dwams57' target=\"_blank\">sweepy-sweep-9</a></strong> to <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/1dwams57' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/1dwams57</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "The model has 5,575,490 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 16.52s\n",
      "\tTrain Loss: 2.728\n",
      "\t Val. Loss: 2.075\n",
      "\t Val. Accuracy: 0.004\n",
      "Epoch: 02 | Time: 0.0m 16.56s\n",
      "\tTrain Loss: 1.772\n",
      "\t Val. Loss: 1.559\n",
      "\t Val. Accuracy: 0.064\n",
      "Epoch: 03 | Time: 0.0m 16.74s\n",
      "\tTrain Loss: 1.378\n",
      "\t Val. Loss: 1.314\n",
      "\t Val. Accuracy: 0.127\n",
      "Epoch: 04 | Time: 0.0m 16.53s\n",
      "\tTrain Loss: 1.163\n",
      "\t Val. Loss: 1.187\n",
      "\t Val. Accuracy: 0.189\n",
      "Epoch: 05 | Time: 0.0m 16.44s\n",
      "\tTrain Loss: 1.037\n",
      "\t Val. Loss: 1.110\n",
      "\t Val. Accuracy: 0.226\n",
      "Epoch: 06 | Time: 0.0m 16.57s\n",
      "\tTrain Loss: 0.949\n",
      "\t Val. Loss: 1.060\n",
      "\t Val. Accuracy: 0.255\n",
      "Epoch: 07 | Time: 0.0m 16.45s\n",
      "\tTrain Loss: 0.868\n",
      "\t Val. Loss: 1.027\n",
      "\t Val. Accuracy: 0.286\n",
      "Epoch: 08 | Time: 0.0m 16.75s\n",
      "\tTrain Loss: 0.815\n",
      "\t Val. Loss: 0.986\n",
      "\t Val. Accuracy: 0.293\n",
      "Epoch: 09 | Time: 0.0m 16.38s\n",
      "\tTrain Loss: 0.770\n",
      "\t Val. Loss: 0.969\n",
      "\t Val. Accuracy: 0.309\n",
      "Epoch: 10 | Time: 0.0m 16.57s\n",
      "\tTrain Loss: 0.723\n",
      "\t Val. Loss: 0.961\n",
      "\t Val. Accuracy: 0.324\n",
      "Epoch: 11 | Time: 0.0m 16.48s\n",
      "\tTrain Loss: 0.684\n",
      "\t Val. Loss: 0.948\n",
      "\t Val. Accuracy: 0.336\n",
      "Epoch: 12 | Time: 0.0m 16.47s\n",
      "\tTrain Loss: 0.649\n",
      "\t Val. Loss: 0.921\n",
      "\t Val. Accuracy: 0.348\n",
      "Epoch: 13 | Time: 0.0m 16.53s\n",
      "\tTrain Loss: 0.614\n",
      "\t Val. Loss: 0.919\n",
      "\t Val. Accuracy: 0.349\n",
      "Epoch: 14 | Time: 0.0m 16.56s\n",
      "\tTrain Loss: 0.586\n",
      "\t Val. Loss: 0.916\n",
      "\t Val. Accuracy: 0.346\n",
      "Epoch: 15 | Time: 0.0m 16.57s\n",
      "\tTrain Loss: 0.561\n",
      "\t Val. Loss: 0.913\n",
      "\t Val. Accuracy: 0.365\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>0.56051</td></tr><tr><td>val_accuracy</td><td>0.36508</td></tr><tr><td>val_loss</td><td>0.91271</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GRU_enc_2_dec_2_hdim_512_emb_256_bs_128_drop_0.3_beam_3_lr_0.0001_clip_5_tf_0.3_epoch_15</strong> at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/1dwams57' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/1dwams57</a><br> View project at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_063752-1dwams57/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: hf5yw71j with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_064229-hf5yw71j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/hf5yw71j' target=\"_blank\">warm-sweep-10</a></strong> to <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/hf5yw71j' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/hf5yw71j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Creating adapter from 3 encoder layers to 1 decoder layers\n",
      "The model has 8,988,482 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 17.88s\n",
      "\tTrain Loss: 2.906\n",
      "\t Val. Loss: 2.407\n",
      "\t Val. Accuracy: 0.002\n",
      "Epoch: 02 | Time: 0.0m 17.84s\n",
      "\tTrain Loss: 1.936\n",
      "\t Val. Loss: 1.844\n",
      "\t Val. Accuracy: 0.050\n",
      "Epoch: 03 | Time: 0.0m 17.96s\n",
      "\tTrain Loss: 1.497\n",
      "\t Val. Loss: 1.572\n",
      "\t Val. Accuracy: 0.104\n",
      "Epoch: 04 | Time: 0.0m 17.76s\n",
      "\tTrain Loss: 1.259\n",
      "\t Val. Loss: 1.419\n",
      "\t Val. Accuracy: 0.156\n",
      "Epoch: 05 | Time: 0.0m 17.90s\n",
      "\tTrain Loss: 1.112\n",
      "\t Val. Loss: 1.312\n",
      "\t Val. Accuracy: 0.194\n",
      "Epoch: 06 | Time: 0.0m 17.82s\n",
      "\tTrain Loss: 0.995\n",
      "\t Val. Loss: 1.234\n",
      "\t Val. Accuracy: 0.228\n",
      "Epoch: 07 | Time: 0.0m 17.77s\n",
      "\tTrain Loss: 0.905\n",
      "\t Val. Loss: 1.199\n",
      "\t Val. Accuracy: 0.246\n",
      "Epoch: 08 | Time: 0.0m 17.91s\n",
      "\tTrain Loss: 0.849\n",
      "\t Val. Loss: 1.154\n",
      "\t Val. Accuracy: 0.270\n",
      "Epoch: 09 | Time: 0.0m 17.71s\n",
      "\tTrain Loss: 0.787\n",
      "\t Val. Loss: 1.138\n",
      "\t Val. Accuracy: 0.274\n",
      "Epoch: 10 | Time: 0.0m 17.92s\n",
      "\tTrain Loss: 0.741\n",
      "\t Val. Loss: 1.116\n",
      "\t Val. Accuracy: 0.292\n",
      "Epoch: 11 | Time: 0.0m 17.97s\n",
      "\tTrain Loss: 0.692\n",
      "\t Val. Loss: 1.093\n",
      "\t Val. Accuracy: 0.305\n",
      "Epoch: 12 | Time: 0.0m 17.74s\n",
      "\tTrain Loss: 0.648\n",
      "\t Val. Loss: 1.087\n",
      "\t Val. Accuracy: 0.310\n",
      "Epoch: 13 | Time: 0.0m 17.81s\n",
      "\tTrain Loss: 0.622\n",
      "\t Val. Loss: 1.062\n",
      "\t Val. Accuracy: 0.316\n",
      "Epoch: 14 | Time: 0.0m 17.78s\n",
      "\tTrain Loss: 0.589\n",
      "\t Val. Loss: 1.058\n",
      "\t Val. Accuracy: 0.332\n",
      "Epoch: 15 | Time: 0.0m 17.88s\n",
      "\tTrain Loss: 0.555\n",
      "\t Val. Loss: 1.062\n",
      "\t Val. Accuracy: 0.325\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>0.55493</td></tr><tr><td>val_accuracy</td><td>0.32515</td></tr><tr><td>val_loss</td><td>1.06176</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LSTM_enc_3_dec_1_hdim_512_emb_256_bs_128_drop_0.3_beam_1_lr_0.0001_clip_5_tf_0.5_epoch_15</strong> at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/hf5yw71j' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/hf5yw71j</a><br> View project at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_064229-hf5yw71j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yx73vzjq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_064726-yx73vzjq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/yx73vzjq' target=\"_blank\">sleek-sweep-11</a></strong> to <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/yx73vzjq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/yx73vzjq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "The model has 2,423,618 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 21.20s\n",
      "\tTrain Loss: 2.577\n",
      "\t Val. Loss: 2.110\n",
      "\t Val. Accuracy: 0.013\n",
      "Epoch: 02 | Time: 0.0m 21.41s\n",
      "\tTrain Loss: 1.607\n",
      "\t Val. Loss: 1.589\n",
      "\t Val. Accuracy: 0.088\n",
      "Epoch: 03 | Time: 0.0m 21.38s\n",
      "\tTrain Loss: 1.227\n",
      "\t Val. Loss: 1.374\n",
      "\t Val. Accuracy: 0.148\n",
      "Epoch: 04 | Time: 0.0m 21.05s\n",
      "\tTrain Loss: 1.032\n",
      "\t Val. Loss: 1.265\n",
      "\t Val. Accuracy: 0.212\n",
      "Epoch: 05 | Time: 0.0m 21.26s\n",
      "\tTrain Loss: 0.903\n",
      "\t Val. Loss: 1.189\n",
      "\t Val. Accuracy: 0.248\n",
      "Epoch: 06 | Time: 0.0m 21.43s\n",
      "\tTrain Loss: 0.819\n",
      "\t Val. Loss: 1.126\n",
      "\t Val. Accuracy: 0.273\n",
      "Epoch: 07 | Time: 0.0m 21.22s\n",
      "\tTrain Loss: 0.753\n",
      "\t Val. Loss: 1.116\n",
      "\t Val. Accuracy: 0.293\n",
      "Epoch: 08 | Time: 0.0m 21.15s\n",
      "\tTrain Loss: 0.701\n",
      "\t Val. Loss: 1.085\n",
      "\t Val. Accuracy: 0.315\n",
      "Epoch: 09 | Time: 0.0m 21.19s\n",
      "\tTrain Loss: 0.656\n",
      "\t Val. Loss: 1.060\n",
      "\t Val. Accuracy: 0.328\n",
      "Epoch: 10 | Time: 0.0m 21.25s\n",
      "\tTrain Loss: 0.613\n",
      "\t Val. Loss: 1.040\n",
      "\t Val. Accuracy: 0.337\n",
      "Epoch: 11 | Time: 0.0m 21.08s\n",
      "\tTrain Loss: 0.577\n",
      "\t Val. Loss: 1.034\n",
      "\t Val. Accuracy: 0.346\n",
      "Epoch: 12 | Time: 0.0m 21.33s\n",
      "\tTrain Loss: 0.544\n",
      "\t Val. Loss: 1.042\n",
      "\t Val. Accuracy: 0.359\n",
      "Epoch: 13 | Time: 0.0m 21.29s\n",
      "\tTrain Loss: 0.526\n",
      "\t Val. Loss: 1.018\n",
      "\t Val. Accuracy: 0.358\n",
      "Epoch: 14 | Time: 0.0m 21.13s\n",
      "\tTrain Loss: 0.499\n",
      "\t Val. Loss: 1.014\n",
      "\t Val. Accuracy: 0.365\n",
      "Epoch: 15 | Time: 0.0m 21.29s\n",
      "\tTrain Loss: 0.471\n",
      "\t Val. Loss: 1.003\n",
      "\t Val. Accuracy: 0.372\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>0.47107</td></tr><tr><td>val_accuracy</td><td>0.37219</td></tr><tr><td>val_loss</td><td>1.00331</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GRU_enc_1_dec_1_hdim_512_emb_256_bs_64_drop_0.3_beam_1_lr_0.0001_clip_5_tf_0.5_epoch_15</strong> at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/yx73vzjq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/yx73vzjq</a><br> View project at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_064726-yx73vzjq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qokesln7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_065319-qokesln7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/qokesln7' target=\"_blank\">whole-sweep-12</a></strong> to <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/qokesln7' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/qokesln7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Creating adapter from 3 encoder layers to 1 decoder layers\n",
      "The model has 8,988,482 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 17.84s\n",
      "\tTrain Loss: 2.920\n",
      "\t Val. Loss: 2.442\n",
      "\t Val. Accuracy: 0.002\n",
      "Epoch: 02 | Time: 0.0m 18.04s\n",
      "\tTrain Loss: 1.944\n",
      "\t Val. Loss: 1.817\n",
      "\t Val. Accuracy: 0.038\n",
      "Epoch: 03 | Time: 0.0m 17.82s\n",
      "\tTrain Loss: 1.497\n",
      "\t Val. Loss: 1.565\n",
      "\t Val. Accuracy: 0.098\n",
      "Epoch: 04 | Time: 0.0m 17.83s\n",
      "\tTrain Loss: 1.264\n",
      "\t Val. Loss: 1.415\n",
      "\t Val. Accuracy: 0.148\n",
      "Epoch: 05 | Time: 0.0m 18.12s\n",
      "\tTrain Loss: 1.113\n",
      "\t Val. Loss: 1.334\n",
      "\t Val. Accuracy: 0.181\n",
      "Epoch: 06 | Time: 0.0m 17.86s\n",
      "\tTrain Loss: 1.018\n",
      "\t Val. Loss: 1.261\n",
      "\t Val. Accuracy: 0.207\n",
      "Epoch: 07 | Time: 0.0m 18.02s\n",
      "\tTrain Loss: 0.926\n",
      "\t Val. Loss: 1.210\n",
      "\t Val. Accuracy: 0.239\n",
      "Epoch: 08 | Time: 0.0m 17.79s\n",
      "\tTrain Loss: 0.853\n",
      "\t Val. Loss: 1.152\n",
      "\t Val. Accuracy: 0.262\n",
      "Epoch: 09 | Time: 0.0m 17.94s\n",
      "\tTrain Loss: 0.798\n",
      "\t Val. Loss: 1.122\n",
      "\t Val. Accuracy: 0.284\n",
      "Epoch: 10 | Time: 0.0m 17.85s\n",
      "\tTrain Loss: 0.743\n",
      "\t Val. Loss: 1.093\n",
      "\t Val. Accuracy: 0.291\n",
      "Epoch: 11 | Time: 0.0m 17.75s\n",
      "\tTrain Loss: 0.704\n",
      "\t Val. Loss: 1.092\n",
      "\t Val. Accuracy: 0.300\n",
      "Epoch: 12 | Time: 0.0m 17.84s\n",
      "\tTrain Loss: 0.663\n",
      "\t Val. Loss: 1.077\n",
      "\t Val. Accuracy: 0.312\n",
      "Epoch: 13 | Time: 0.0m 17.79s\n",
      "\tTrain Loss: 0.624\n",
      "\t Val. Loss: 1.076\n",
      "\t Val. Accuracy: 0.320\n",
      "Epoch: 14 | Time: 0.0m 18.10s\n",
      "\tTrain Loss: 0.589\n",
      "\t Val. Loss: 1.048\n",
      "\t Val. Accuracy: 0.332\n",
      "Epoch: 15 | Time: 0.0m 18.02s\n",
      "\tTrain Loss: 0.560\n",
      "\t Val. Loss: 1.055\n",
      "\t Val. Accuracy: 0.326\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>0.55953</td></tr><tr><td>val_accuracy</td><td>0.32584</td></tr><tr><td>val_loss</td><td>1.05455</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LSTM_enc_3_dec_1_hdim_512_emb_256_bs_128_drop_0.3_beam_1_lr_0.0001_clip_5_tf_0.5_epoch_15</strong> at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/qokesln7' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/qokesln7</a><br> View project at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_065319-qokesln7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wlh65bd8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_065820-wlh65bd8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/wlh65bd8' target=\"_blank\">woven-sweep-13</a></strong> to <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/wlh65bd8' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/wlh65bd8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "The model has 3,212,098 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 14.75s\n",
      "\tTrain Loss: 1.740\n",
      "\t Val. Loss: 1.220\n",
      "\t Val. Accuracy: 0.174\n",
      "Epoch: 02 | Time: 0.0m 14.52s\n",
      "\tTrain Loss: 0.935\n",
      "\t Val. Loss: 1.037\n",
      "\t Val. Accuracy: 0.278\n",
      "Epoch: 03 | Time: 0.0m 14.66s\n",
      "\tTrain Loss: 0.740\n",
      "\t Val. Loss: 0.975\n",
      "\t Val. Accuracy: 0.298\n",
      "Epoch: 04 | Time: 0.0m 14.56s\n",
      "\tTrain Loss: 0.627\n",
      "\t Val. Loss: 0.985\n",
      "\t Val. Accuracy: 0.317\n",
      "Epoch: 05 | Time: 0.0m 14.72s\n",
      "\tTrain Loss: 0.538\n",
      "\t Val. Loss: 0.963\n",
      "\t Val. Accuracy: 0.349\n",
      "Epoch: 06 | Time: 0.0m 14.56s\n",
      "\tTrain Loss: 0.477\n",
      "\t Val. Loss: 0.943\n",
      "\t Val. Accuracy: 0.351\n",
      "Epoch: 07 | Time: 0.0m 14.52s\n",
      "\tTrain Loss: 0.411\n",
      "\t Val. Loss: 0.970\n",
      "\t Val. Accuracy: 0.350\n",
      "Epoch: 08 | Time: 0.0m 14.47s\n",
      "\tTrain Loss: 0.372\n",
      "\t Val. Loss: 0.978\n",
      "\t Val. Accuracy: 0.355\n",
      "Epoch: 09 | Time: 0.0m 14.78s\n",
      "\tTrain Loss: 0.333\n",
      "\t Val. Loss: 1.008\n",
      "\t Val. Accuracy: 0.358\n",
      "Epoch: 10 | Time: 0.0m 14.49s\n",
      "\tTrain Loss: 0.297\n",
      "\t Val. Loss: 1.017\n",
      "\t Val. Accuracy: 0.351\n",
      "Epoch: 11 | Time: 0.0m 14.62s\n",
      "\tTrain Loss: 0.266\n",
      "\t Val. Loss: 1.031\n",
      "\t Val. Accuracy: 0.343\n",
      "Epoch: 12 | Time: 0.0m 14.38s\n",
      "\tTrain Loss: 0.241\n",
      "\t Val. Loss: 1.092\n",
      "\t Val. Accuracy: 0.347\n",
      "Epoch: 13 | Time: 0.0m 14.69s\n",
      "\tTrain Loss: 0.225\n",
      "\t Val. Loss: 1.109\n",
      "\t Val. Accuracy: 0.356\n",
      "Epoch: 14 | Time: 0.0m 14.50s\n",
      "\tTrain Loss: 0.203\n",
      "\t Val. Loss: 1.148\n",
      "\t Val. Accuracy: 0.356\n",
      "Epoch: 15 | Time: 0.0m 14.51s\n",
      "\tTrain Loss: 0.194\n",
      "\t Val. Loss: 1.177\n",
      "\t Val. Accuracy: 0.349\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>0.19439</td></tr><tr><td>val_accuracy</td><td>0.34924</td></tr><tr><td>val_loss</td><td>1.17654</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LSTM_enc_1_dec_1_hdim_512_emb_256_bs_128_drop_0.3_beam_1_lr_0.001_clip_5_tf_0.3_epoch_15</strong> at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/wlh65bd8' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/wlh65bd8</a><br> View project at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_065820-wlh65bd8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 80e9cf1i with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_070228-80e9cf1i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/80e9cf1i' target=\"_blank\">flowing-sweep-14</a></strong> to <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/80e9cf1i' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/80e9cf1i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Creating adapter from 1 encoder layers to 3 decoder layers\n",
      "The model has 2,541,378 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 17.91s\n",
      "\tTrain Loss: 3.118\n",
      "\t Val. Loss: 2.668\n",
      "\t Val. Accuracy: 0.000\n",
      "Epoch: 02 | Time: 0.0m 17.71s\n",
      "\tTrain Loss: 2.398\n",
      "\t Val. Loss: 2.210\n",
      "\t Val. Accuracy: 0.005\n",
      "Epoch: 03 | Time: 0.0m 18.01s\n",
      "\tTrain Loss: 1.990\n",
      "\t Val. Loss: 2.008\n",
      "\t Val. Accuracy: 0.021\n",
      "Epoch: 04 | Time: 0.0m 17.77s\n",
      "\tTrain Loss: 1.720\n",
      "\t Val. Loss: 1.849\n",
      "\t Val. Accuracy: 0.046\n",
      "Epoch: 05 | Time: 0.0m 17.88s\n",
      "\tTrain Loss: 1.525\n",
      "\t Val. Loss: 1.736\n",
      "\t Val. Accuracy: 0.070\n",
      "Epoch: 06 | Time: 0.0m 17.91s\n",
      "\tTrain Loss: 1.372\n",
      "\t Val. Loss: 1.665\n",
      "\t Val. Accuracy: 0.101\n",
      "Epoch: 07 | Time: 0.0m 17.64s\n",
      "\tTrain Loss: 1.270\n",
      "\t Val. Loss: 1.585\n",
      "\t Val. Accuracy: 0.124\n",
      "Epoch: 08 | Time: 0.0m 17.91s\n",
      "\tTrain Loss: 1.182\n",
      "\t Val. Loss: 1.545\n",
      "\t Val. Accuracy: 0.145\n",
      "Epoch: 09 | Time: 0.0m 17.70s\n",
      "\tTrain Loss: 1.107\n",
      "\t Val. Loss: 1.482\n",
      "\t Val. Accuracy: 0.165\n",
      "Epoch: 10 | Time: 0.0m 17.79s\n",
      "\tTrain Loss: 1.048\n",
      "\t Val. Loss: 1.444\n",
      "\t Val. Accuracy: 0.179\n",
      "Epoch: 11 | Time: 0.0m 17.87s\n",
      "\tTrain Loss: 0.993\n",
      "\t Val. Loss: 1.405\n",
      "\t Val. Accuracy: 0.201\n",
      "Epoch: 12 | Time: 0.0m 17.69s\n",
      "\tTrain Loss: 0.938\n",
      "\t Val. Loss: 1.404\n",
      "\t Val. Accuracy: 0.214\n",
      "Epoch: 13 | Time: 0.0m 17.96s\n",
      "\tTrain Loss: 0.895\n",
      "\t Val. Loss: 1.380\n",
      "\t Val. Accuracy: 0.235\n",
      "Epoch: 14 | Time: 0.0m 17.71s\n",
      "\tTrain Loss: 0.856\n",
      "\t Val. Loss: 1.363\n",
      "\t Val. Accuracy: 0.241\n",
      "Epoch: 15 | Time: 0.0m 17.90s\n",
      "\tTrain Loss: 0.840\n",
      "\t Val. Loss: 1.332\n",
      "\t Val. Accuracy: 0.250\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>0.83997</td></tr><tr><td>val_accuracy</td><td>0.24966</td></tr><tr><td>val_loss</td><td>1.33225</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LSTM_enc_1_dec_3_hdim_256_emb_256_bs_128_drop_0.3_beam_1_lr_0.0001_clip_1_tf_0.7_epoch_15</strong> at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/80e9cf1i' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/80e9cf1i</a><br> View project at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_070228-80e9cf1i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 390xenm0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_070742-390xenm0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/390xenm0' target=\"_blank\">super-sweep-15</a></strong> to <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/390xenm0' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/390xenm0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "The model has 7,414,594 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 45.78s\n",
      "\tTrain Loss: 2.118\n",
      "\t Val. Loss: 1.519\n",
      "\t Val. Accuracy: 0.068\n",
      "Epoch: 02 | Time: 0.0m 45.96s\n",
      "\tTrain Loss: 1.318\n",
      "\t Val. Loss: 1.228\n",
      "\t Val. Accuracy: 0.160\n",
      "Epoch: 03 | Time: 0.0m 46.02s\n",
      "\tTrain Loss: 1.063\n",
      "\t Val. Loss: 1.121\n",
      "\t Val. Accuracy: 0.220\n",
      "Epoch: 04 | Time: 0.0m 45.98s\n",
      "\tTrain Loss: 0.918\n",
      "\t Val. Loss: 1.031\n",
      "\t Val. Accuracy: 0.261\n",
      "Epoch: 05 | Time: 0.0m 45.76s\n",
      "\tTrain Loss: 0.812\n",
      "\t Val. Loss: 0.973\n",
      "\t Val. Accuracy: 0.299\n",
      "Epoch: 06 | Time: 0.0m 45.84s\n",
      "\tTrain Loss: 0.733\n",
      "\t Val. Loss: 0.948\n",
      "\t Val. Accuracy: 0.306\n",
      "Epoch: 07 | Time: 0.0m 45.75s\n",
      "\tTrain Loss: 0.662\n",
      "\t Val. Loss: 0.933\n",
      "\t Val. Accuracy: 0.319\n",
      "Epoch: 08 | Time: 0.0m 45.79s\n",
      "\tTrain Loss: 0.602\n",
      "\t Val. Loss: 0.936\n",
      "\t Val. Accuracy: 0.344\n",
      "Epoch: 09 | Time: 0.0m 45.67s\n",
      "\tTrain Loss: 0.550\n",
      "\t Val. Loss: 0.935\n",
      "\t Val. Accuracy: 0.345\n",
      "Epoch: 10 | Time: 0.0m 45.84s\n",
      "\tTrain Loss: 0.508\n",
      "\t Val. Loss: 0.930\n",
      "\t Val. Accuracy: 0.347\n",
      "Epoch: 11 | Time: 0.0m 45.64s\n",
      "\tTrain Loss: 0.462\n",
      "\t Val. Loss: 0.950\n",
      "\t Val. Accuracy: 0.359\n",
      "Epoch: 12 | Time: 0.0m 45.91s\n",
      "\tTrain Loss: 0.424\n",
      "\t Val. Loss: 0.966\n",
      "\t Val. Accuracy: 0.355\n",
      "Epoch: 13 | Time: 0.0m 46.04s\n",
      "\tTrain Loss: 0.389\n",
      "\t Val. Loss: 0.972\n",
      "\t Val. Accuracy: 0.355\n",
      "Epoch: 14 | Time: 0.0m 45.83s\n",
      "\tTrain Loss: 0.356\n",
      "\t Val. Loss: 0.994\n",
      "\t Val. Accuracy: 0.366\n",
      "Epoch: 15 | Time: 0.0m 45.85s\n",
      "\tTrain Loss: 0.327\n",
      "\t Val. Loss: 0.981\n",
      "\t Val. Accuracy: 0.364\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>0.32691</td></tr><tr><td>val_accuracy</td><td>0.3637</td></tr><tr><td>val_loss</td><td>0.98082</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LSTM_enc_2_dec_2_hdim_512_emb_256_bs_32_drop_0.3_beam_1_lr_0.0001_clip_5_tf_0.3_epoch_15</strong> at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/390xenm0' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/390xenm0</a><br> View project at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_070742-390xenm0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nor46v7s with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_071952-nor46v7s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/nor46v7s' target=\"_blank\">zesty-sweep-16</a></strong> to <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/nor46v7s' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/nor46v7s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "The model has 7,414,594 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 27.86s\n",
      "\tTrain Loss: 1.505\n",
      "\t Val. Loss: 1.066\n",
      "\t Val. Accuracy: 0.259\n",
      "Epoch: 02 | Time: 0.0m 27.78s\n",
      "\tTrain Loss: 0.780\n",
      "\t Val. Loss: 0.931\n",
      "\t Val. Accuracy: 0.322\n",
      "Epoch: 03 | Time: 0.0m 27.70s\n",
      "\tTrain Loss: 0.605\n",
      "\t Val. Loss: 0.915\n",
      "\t Val. Accuracy: 0.353\n",
      "Epoch: 04 | Time: 0.0m 27.61s\n",
      "\tTrain Loss: 0.498\n",
      "\t Val. Loss: 0.915\n",
      "\t Val. Accuracy: 0.362\n",
      "Epoch: 05 | Time: 0.0m 27.85s\n",
      "\tTrain Loss: 0.409\n",
      "\t Val. Loss: 0.950\n",
      "\t Val. Accuracy: 0.370\n",
      "Epoch: 06 | Time: 0.0m 27.72s\n",
      "\tTrain Loss: 0.346\n",
      "\t Val. Loss: 0.982\n",
      "\t Val. Accuracy: 0.364\n",
      "Epoch: 07 | Time: 0.0m 27.91s\n",
      "\tTrain Loss: 0.300\n",
      "\t Val. Loss: 0.978\n",
      "\t Val. Accuracy: 0.377\n",
      "Epoch: 08 | Time: 0.0m 27.76s\n",
      "\tTrain Loss: 0.262\n",
      "\t Val. Loss: 1.052\n",
      "\t Val. Accuracy: 0.367\n",
      "Epoch: 09 | Time: 0.0m 27.99s\n",
      "\tTrain Loss: 0.236\n",
      "\t Val. Loss: 1.075\n",
      "\t Val. Accuracy: 0.371\n",
      "Epoch: 10 | Time: 0.0m 27.92s\n",
      "\tTrain Loss: 0.219\n",
      "\t Val. Loss: 1.098\n",
      "\t Val. Accuracy: 0.359\n",
      "Epoch: 11 | Time: 0.0m 27.96s\n",
      "\tTrain Loss: 0.197\n",
      "\t Val. Loss: 1.151\n",
      "\t Val. Accuracy: 0.356\n",
      "Epoch: 12 | Time: 0.0m 28.00s\n",
      "\tTrain Loss: 0.188\n",
      "\t Val. Loss: 1.205\n",
      "\t Val. Accuracy: 0.353\n",
      "Epoch: 13 | Time: 0.0m 28.09s\n",
      "\tTrain Loss: 0.183\n",
      "\t Val. Loss: 1.161\n",
      "\t Val. Accuracy: 0.353\n",
      "Epoch: 14 | Time: 0.0m 27.96s\n",
      "\tTrain Loss: 0.172\n",
      "\t Val. Loss: 1.211\n",
      "\t Val. Accuracy: 0.357\n",
      "Epoch: 15 | Time: 0.0m 27.84s\n",
      "\tTrain Loss: 0.160\n",
      "\t Val. Loss: 1.239\n",
      "\t Val. Accuracy: 0.353\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>0.16007</td></tr><tr><td>val_accuracy</td><td>0.35291</td></tr><tr><td>val_loss</td><td>1.23868</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LSTM_enc_2_dec_2_hdim_512_emb_256_bs_64_drop_0.3_beam_1_lr_0.001_clip_5_tf_0.3_epoch_15</strong> at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/nor46v7s' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/nor46v7s</a><br> View project at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_071952-nor46v7s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qy3p2yfx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_072731-qy3p2yfx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/qy3p2yfx' target=\"_blank\">vital-sweep-17</a></strong> to <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/qy3p2yfx' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/qy3p2yfx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "The model has 3,212,098 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 14.57s\n",
      "\tTrain Loss: 2.802\n",
      "\t Val. Loss: 2.242\n",
      "\t Val. Accuracy: 0.008\n",
      "Epoch: 02 | Time: 0.0m 14.78s\n",
      "\tTrain Loss: 1.878\n",
      "\t Val. Loss: 1.836\n",
      "\t Val. Accuracy: 0.046\n",
      "Epoch: 03 | Time: 0.0m 14.56s\n",
      "\tTrain Loss: 1.521\n",
      "\t Val. Loss: 1.614\n",
      "\t Val. Accuracy: 0.086\n",
      "Epoch: 04 | Time: 0.0m 14.73s\n",
      "\tTrain Loss: 1.322\n",
      "\t Val. Loss: 1.482\n",
      "\t Val. Accuracy: 0.134\n",
      "Epoch: 05 | Time: 0.0m 14.65s\n",
      "\tTrain Loss: 1.182\n",
      "\t Val. Loss: 1.374\n",
      "\t Val. Accuracy: 0.164\n",
      "Epoch: 06 | Time: 0.0m 14.93s\n",
      "\tTrain Loss: 1.075\n",
      "\t Val. Loss: 1.321\n",
      "\t Val. Accuracy: 0.182\n",
      "Epoch: 07 | Time: 0.0m 14.47s\n",
      "\tTrain Loss: 1.003\n",
      "\t Val. Loss: 1.262\n",
      "\t Val. Accuracy: 0.206\n",
      "Epoch: 08 | Time: 0.0m 14.63s\n",
      "\tTrain Loss: 0.924\n",
      "\t Val. Loss: 1.211\n",
      "\t Val. Accuracy: 0.234\n",
      "Epoch: 09 | Time: 0.0m 14.55s\n",
      "\tTrain Loss: 0.876\n",
      "\t Val. Loss: 1.181\n",
      "\t Val. Accuracy: 0.245\n",
      "Epoch: 10 | Time: 0.0m 14.64s\n",
      "\tTrain Loss: 0.825\n",
      "\t Val. Loss: 1.165\n",
      "\t Val. Accuracy: 0.270\n",
      "Epoch: 11 | Time: 0.0m 14.62s\n",
      "\tTrain Loss: 0.782\n",
      "\t Val. Loss: 1.139\n",
      "\t Val. Accuracy: 0.273\n",
      "Epoch: 12 | Time: 0.0m 14.61s\n",
      "\tTrain Loss: 0.740\n",
      "\t Val. Loss: 1.113\n",
      "\t Val. Accuracy: 0.292\n",
      "Epoch: 13 | Time: 0.0m 14.57s\n",
      "\tTrain Loss: 0.715\n",
      "\t Val. Loss: 1.105\n",
      "\t Val. Accuracy: 0.303\n",
      "Epoch: 14 | Time: 0.0m 14.45s\n",
      "\tTrain Loss: 0.682\n",
      "\t Val. Loss: 1.101\n",
      "\t Val. Accuracy: 0.307\n",
      "Epoch: 15 | Time: 0.0m 14.49s\n",
      "\tTrain Loss: 0.658\n",
      "\t Val. Loss: 1.090\n",
      "\t Val. Accuracy: 0.315\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>0.65805</td></tr><tr><td>val_accuracy</td><td>0.31482</td></tr><tr><td>val_loss</td><td>1.09038</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LSTM_enc_1_dec_1_hdim_512_emb_256_bs_128_drop_0.3_beam_1_lr_0.0001_clip_5_tf_0.5_epoch_15</strong> at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/qy3p2yfx' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/qy3p2yfx</a><br> View project at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_072731-qy3p2yfx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9nm0cwzm with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_073138-9nm0cwzm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/9nm0cwzm' target=\"_blank\">happy-sweep-18</a></strong> to <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/9nm0cwzm' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/9nm0cwzm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Creating adapter from 1 encoder layers to 2 decoder layers\n",
      "The model has 6,363,970 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 26.86s\n",
      "\tTrain Loss: 2.533\n",
      "\t Val. Loss: 1.935\n",
      "\t Val. Accuracy: 0.019\n",
      "Epoch: 02 | Time: 0.0m 26.63s\n",
      "\tTrain Loss: 1.681\n",
      "\t Val. Loss: 1.539\n",
      "\t Val. Accuracy: 0.072\n",
      "Epoch: 03 | Time: 0.0m 26.59s\n",
      "\tTrain Loss: 1.375\n",
      "\t Val. Loss: 1.333\n",
      "\t Val. Accuracy: 0.126\n",
      "Epoch: 04 | Time: 0.0m 26.37s\n",
      "\tTrain Loss: 1.182\n",
      "\t Val. Loss: 1.239\n",
      "\t Val. Accuracy: 0.162\n",
      "Epoch: 05 | Time: 0.0m 26.57s\n",
      "\tTrain Loss: 1.065\n",
      "\t Val. Loss: 1.164\n",
      "\t Val. Accuracy: 0.203\n",
      "Epoch: 06 | Time: 0.0m 26.52s\n",
      "\tTrain Loss: 0.976\n",
      "\t Val. Loss: 1.123\n",
      "\t Val. Accuracy: 0.221\n",
      "Epoch: 07 | Time: 0.0m 26.51s\n",
      "\tTrain Loss: 0.895\n",
      "\t Val. Loss: 1.080\n",
      "\t Val. Accuracy: 0.248\n",
      "Epoch: 08 | Time: 0.0m 26.40s\n",
      "\tTrain Loss: 0.838\n",
      "\t Val. Loss: 1.045\n",
      "\t Val. Accuracy: 0.261\n",
      "Epoch: 09 | Time: 0.0m 26.52s\n",
      "\tTrain Loss: 0.778\n",
      "\t Val. Loss: 1.022\n",
      "\t Val. Accuracy: 0.279\n",
      "Epoch: 10 | Time: 0.0m 26.45s\n",
      "\tTrain Loss: 0.731\n",
      "\t Val. Loss: 1.004\n",
      "\t Val. Accuracy: 0.292\n",
      "Epoch: 11 | Time: 0.0m 26.50s\n",
      "\tTrain Loss: 0.679\n",
      "\t Val. Loss: 1.007\n",
      "\t Val. Accuracy: 0.301\n",
      "Epoch: 12 | Time: 0.0m 26.50s\n",
      "\tTrain Loss: 0.646\n",
      "\t Val. Loss: 0.988\n",
      "\t Val. Accuracy: 0.306\n",
      "Epoch: 13 | Time: 0.0m 26.33s\n",
      "\tTrain Loss: 0.605\n",
      "\t Val. Loss: 0.991\n",
      "\t Val. Accuracy: 0.317\n",
      "Epoch: 14 | Time: 0.0m 26.60s\n",
      "\tTrain Loss: 0.572\n",
      "\t Val. Loss: 0.976\n",
      "\t Val. Accuracy: 0.318\n",
      "Epoch: 15 | Time: 0.0m 26.49s\n",
      "\tTrain Loss: 0.539\n",
      "\t Val. Loss: 0.959\n",
      "\t Val. Accuracy: 0.333\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>0.53858</td></tr><tr><td>val_accuracy</td><td>0.33272</td></tr><tr><td>val_loss</td><td>0.95884</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LSTM_enc_1_dec_2_hdim_512_emb_256_bs_64_drop_0.3_beam_1_lr_0.0001_clip_5_tf_0.3_epoch_15</strong> at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/9nm0cwzm' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/9nm0cwzm</a><br> View project at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_073138-9nm0cwzm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: uldz0mh0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_073856-uldz0mh0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/uldz0mh0' target=\"_blank\">wild-sweep-19</a></strong> to <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/uldz0mh0' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/uldz0mh0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "The model has 7,414,594 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 28.02s\n",
      "\tTrain Loss: 2.389\n",
      "\t Val. Loss: 1.765\n",
      "\t Val. Accuracy: 0.034\n",
      "Epoch: 02 | Time: 0.0m 27.84s\n",
      "\tTrain Loss: 1.490\n",
      "\t Val. Loss: 1.363\n",
      "\t Val. Accuracy: 0.099\n",
      "Epoch: 03 | Time: 0.0m 27.99s\n",
      "\tTrain Loss: 1.195\n",
      "\t Val. Loss: 1.196\n",
      "\t Val. Accuracy: 0.189\n",
      "Epoch: 04 | Time: 0.0m 27.88s\n",
      "\tTrain Loss: 1.020\n",
      "\t Val. Loss: 1.108\n",
      "\t Val. Accuracy: 0.227\n",
      "Epoch: 05 | Time: 0.0m 27.85s\n",
      "\tTrain Loss: 0.911\n",
      "\t Val. Loss: 1.058\n",
      "\t Val. Accuracy: 0.256\n",
      "Epoch: 06 | Time: 0.0m 27.72s\n",
      "\tTrain Loss: 0.825\n",
      "\t Val. Loss: 1.009\n",
      "\t Val. Accuracy: 0.285\n",
      "Epoch: 07 | Time: 0.0m 27.75s\n",
      "\tTrain Loss: 0.758\n",
      "\t Val. Loss: 0.993\n",
      "\t Val. Accuracy: 0.292\n",
      "Epoch: 08 | Time: 0.0m 27.60s\n",
      "\tTrain Loss: 0.692\n",
      "\t Val. Loss: 0.968\n",
      "\t Val. Accuracy: 0.311\n",
      "Epoch: 09 | Time: 0.0m 27.85s\n",
      "\tTrain Loss: 0.641\n",
      "\t Val. Loss: 0.971\n",
      "\t Val. Accuracy: 0.326\n",
      "Epoch: 10 | Time: 0.0m 27.59s\n",
      "\tTrain Loss: 0.592\n",
      "\t Val. Loss: 0.951\n",
      "\t Val. Accuracy: 0.333\n",
      "Epoch: 11 | Time: 0.0m 27.83s\n",
      "\tTrain Loss: 0.554\n",
      "\t Val. Loss: 0.947\n",
      "\t Val. Accuracy: 0.338\n",
      "Epoch: 12 | Time: 0.0m 27.76s\n",
      "\tTrain Loss: 0.510\n",
      "\t Val. Loss: 0.950\n",
      "\t Val. Accuracy: 0.360\n",
      "Epoch: 13 | Time: 0.0m 27.85s\n",
      "\tTrain Loss: 0.475\n",
      "\t Val. Loss: 0.945\n",
      "\t Val. Accuracy: 0.356\n",
      "Epoch: 14 | Time: 0.0m 27.81s\n",
      "\tTrain Loss: 0.444\n",
      "\t Val. Loss: 0.949\n",
      "\t Val. Accuracy: 0.359\n",
      "Epoch: 15 | Time: 0.0m 28.09s\n",
      "\tTrain Loss: 0.413\n",
      "\t Val. Loss: 0.985\n",
      "\t Val. Accuracy: 0.356\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>0.41272</td></tr><tr><td>val_accuracy</td><td>0.35613</td></tr><tr><td>val_loss</td><td>0.9847</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LSTM_enc_2_dec_2_hdim_512_emb_256_bs_64_drop_0.2_beam_1_lr_0.0001_clip_5_tf_0.3_epoch_15</strong> at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/uldz0mh0' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/uldz0mh0</a><br> View project at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_073856-uldz0mh0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: eqnt770p with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_074625-eqnt770p</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/eqnt770p' target=\"_blank\">crimson-sweep-20</a></strong> to <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/eqnt770p' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/eqnt770p</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Creating adapter from 2 encoder layers to 3 decoder layers\n",
      "The model has 8,725,826 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 18.84s\n",
      "\tTrain Loss: 2.661\n",
      "\t Val. Loss: 1.998\n",
      "\t Val. Accuracy: 0.006\n",
      "Epoch: 02 | Time: 0.0m 19.01s\n",
      "\tTrain Loss: 1.723\n",
      "\t Val. Loss: 1.494\n",
      "\t Val. Accuracy: 0.066\n",
      "Epoch: 03 | Time: 0.0m 18.85s\n",
      "\tTrain Loss: 1.351\n",
      "\t Val. Loss: 1.317\n",
      "\t Val. Accuracy: 0.117\n",
      "Epoch: 04 | Time: 0.0m 18.86s\n",
      "\tTrain Loss: 1.165\n",
      "\t Val. Loss: 1.199\n",
      "\t Val. Accuracy: 0.165\n",
      "Epoch: 05 | Time: 0.0m 19.03s\n",
      "\tTrain Loss: 1.042\n",
      "\t Val. Loss: 1.129\n",
      "\t Val. Accuracy: 0.214\n",
      "Epoch: 06 | Time: 0.0m 18.77s\n",
      "\tTrain Loss: 0.948\n",
      "\t Val. Loss: 1.084\n",
      "\t Val. Accuracy: 0.241\n",
      "Epoch: 07 | Time: 0.0m 18.88s\n",
      "\tTrain Loss: 0.889\n",
      "\t Val. Loss: 1.042\n",
      "\t Val. Accuracy: 0.263\n",
      "Epoch: 08 | Time: 0.0m 18.93s\n",
      "\tTrain Loss: 0.820\n",
      "\t Val. Loss: 1.035\n",
      "\t Val. Accuracy: 0.277\n",
      "Epoch: 09 | Time: 0.0m 18.85s\n",
      "\tTrain Loss: 0.781\n",
      "\t Val. Loss: 1.006\n",
      "\t Val. Accuracy: 0.295\n",
      "Epoch: 10 | Time: 0.0m 19.05s\n",
      "\tTrain Loss: 0.735\n",
      "\t Val. Loss: 1.006\n",
      "\t Val. Accuracy: 0.297\n",
      "Epoch: 11 | Time: 0.0m 18.79s\n",
      "\tTrain Loss: 0.695\n",
      "\t Val. Loss: 0.996\n",
      "\t Val. Accuracy: 0.306\n",
      "Epoch: 12 | Time: 0.0m 18.92s\n",
      "\tTrain Loss: 0.664\n",
      "\t Val. Loss: 0.966\n",
      "\t Val. Accuracy: 0.314\n",
      "Epoch: 13 | Time: 0.0m 19.20s\n",
      "\tTrain Loss: 0.621\n",
      "\t Val. Loss: 0.973\n",
      "\t Val. Accuracy: 0.321\n",
      "Epoch: 14 | Time: 0.0m 19.10s\n",
      "\tTrain Loss: 0.592\n",
      "\t Val. Loss: 0.957\n",
      "\t Val. Accuracy: 0.330\n",
      "Epoch: 15 | Time: 0.0m 19.04s\n",
      "\tTrain Loss: 0.562\n",
      "\t Val. Loss: 0.966\n",
      "\t Val. Accuracy: 0.340\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>0.56174</td></tr><tr><td>val_accuracy</td><td>0.34029</td></tr><tr><td>val_loss</td><td>0.966</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GRU_enc_2_dec_3_hdim_512_emb_256_bs_128_drop_0.3_beam_1_lr_0.0001_clip_5_tf_0.3_epoch_15</strong> at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/eqnt770p' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/eqnt770p</a><br> View project at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_074625-eqnt770p/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2it2uiu5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_075137-2it2uiu5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/2it2uiu5' target=\"_blank\">frosty-sweep-21</a></strong> to <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/2it2uiu5' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/2it2uiu5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "The model has 3,212,098 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 35.97s\n",
      "\tTrain Loss: 2.308\n",
      "\t Val. Loss: 1.756\n",
      "\t Val. Accuracy: 0.036\n",
      "Epoch: 02 | Time: 0.0m 35.90s\n",
      "\tTrain Loss: 1.530\n",
      "\t Val. Loss: 1.412\n",
      "\t Val. Accuracy: 0.103\n",
      "Epoch: 03 | Time: 0.0m 35.81s\n",
      "\tTrain Loss: 1.246\n",
      "\t Val. Loss: 1.242\n",
      "\t Val. Accuracy: 0.166\n",
      "Epoch: 04 | Time: 0.0m 35.89s\n",
      "\tTrain Loss: 1.074\n",
      "\t Val. Loss: 1.142\n",
      "\t Val. Accuracy: 0.211\n",
      "Epoch: 05 | Time: 0.0m 35.81s\n",
      "\tTrain Loss: 0.968\n",
      "\t Val. Loss: 1.098\n",
      "\t Val. Accuracy: 0.235\n",
      "Epoch: 06 | Time: 0.0m 35.89s\n",
      "\tTrain Loss: 0.882\n",
      "\t Val. Loss: 1.048\n",
      "\t Val. Accuracy: 0.263\n",
      "Epoch: 07 | Time: 0.0m 35.78s\n",
      "\tTrain Loss: 0.813\n",
      "\t Val. Loss: 1.027\n",
      "\t Val. Accuracy: 0.283\n",
      "Epoch: 08 | Time: 0.0m 35.88s\n",
      "\tTrain Loss: 0.755\n",
      "\t Val. Loss: 0.994\n",
      "\t Val. Accuracy: 0.297\n",
      "Epoch: 09 | Time: 0.0m 35.92s\n",
      "\tTrain Loss: 0.699\n",
      "\t Val. Loss: 0.984\n",
      "\t Val. Accuracy: 0.314\n",
      "Epoch: 10 | Time: 0.0m 35.73s\n",
      "\tTrain Loss: 0.657\n",
      "\t Val. Loss: 0.975\n",
      "\t Val. Accuracy: 0.312\n",
      "Epoch: 11 | Time: 0.0m 35.82s\n",
      "\tTrain Loss: 0.618\n",
      "\t Val. Loss: 0.962\n",
      "\t Val. Accuracy: 0.327\n",
      "Epoch: 12 | Time: 0.0m 36.17s\n",
      "\tTrain Loss: 0.576\n",
      "\t Val. Loss: 0.980\n",
      "\t Val. Accuracy: 0.331\n",
      "Epoch: 13 | Time: 0.0m 35.99s\n",
      "\tTrain Loss: 0.546\n",
      "\t Val. Loss: 0.978\n",
      "\t Val. Accuracy: 0.337\n",
      "Epoch: 14 | Time: 0.0m 36.07s\n",
      "\tTrain Loss: 0.514\n",
      "\t Val. Loss: 0.967\n",
      "\t Val. Accuracy: 0.342\n",
      "Epoch: 15 | Time: 0.0m 36.07s\n",
      "\tTrain Loss: 0.484\n",
      "\t Val. Loss: 0.976\n",
      "\t Val. Accuracy: 0.352\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>0.48379</td></tr><tr><td>val_accuracy</td><td>0.352</td></tr><tr><td>val_loss</td><td>0.97644</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LSTM_enc_1_dec_1_hdim_512_emb_256_bs_32_drop_0.3_beam_1_lr_0.0001_clip_0.1_tf_0.3_epoch_15</strong> at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/2it2uiu5' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/2it2uiu5</a><br> View project at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_075137-2it2uiu5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 03u4qjpd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tclip: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_080117-03u4qjpd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/03u4qjpd' target=\"_blank\">amber-sweep-22</a></strong> to <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/sweeps/r9ulhvpq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/03u4qjpd' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/03u4qjpd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pandas/core/computation/expressions.py:73: RuntimeWarning: invalid value encountered in less_equal\n",
      "  return op(a, b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Latin vocabulary size: 29\n",
      "Devanagari vocabulary size: 66\n",
      "Special tokens: PAD=<PAD> (idx=0), SOS=<SOS> (idx=1), EOS=<EOS> (idx=2)\n",
      "Creating adapter from 3 encoder layers to 2 decoder layers\n",
      "The model has 8,725,314 trainable parameters\n",
      "Epoch: 01 | Time: 0.0m 28.38s\n",
      "\tTrain Loss: 2.213\n",
      "\t Val. Loss: 1.653\n",
      "\t Val. Accuracy: 0.076\n",
      "Epoch: 02 | Time: 0.0m 28.07s\n",
      "\tTrain Loss: 1.282\n",
      "\t Val. Loss: 1.341\n",
      "\t Val. Accuracy: 0.165\n",
      "Epoch: 03 | Time: 0.0m 28.07s\n",
      "\tTrain Loss: 1.014\n",
      "\t Val. Loss: 1.225\n",
      "\t Val. Accuracy: 0.227\n",
      "Epoch: 04 | Time: 0.0m 28.05s\n",
      "\tTrain Loss: 0.871\n",
      "\t Val. Loss: 1.140\n",
      "\t Val. Accuracy: 0.271\n",
      "Epoch: 05 | Time: 0.0m 28.10s\n",
      "\tTrain Loss: 0.766\n",
      "\t Val. Loss: 1.104\n",
      "\t Val. Accuracy: 0.296\n",
      "Epoch: 06 | Time: 0.0m 28.20s\n",
      "\tTrain Loss: 0.694\n",
      "\t Val. Loss: 1.068\n",
      "\t Val. Accuracy: 0.313\n",
      "Epoch: 07 | Time: 0.0m 28.10s\n",
      "\tTrain Loss: 0.631\n",
      "\t Val. Loss: 1.085\n",
      "\t Val. Accuracy: 0.315\n",
      "Epoch: 08 | Time: 0.0m 28.18s\n",
      "\tTrain Loss: 0.583\n",
      "\t Val. Loss: 1.060\n",
      "\t Val. Accuracy: 0.346\n",
      "Epoch: 09 | Time: 0.0m 28.15s\n",
      "\tTrain Loss: 0.537\n",
      "\t Val. Loss: 1.068\n",
      "\t Val. Accuracy: 0.358\n",
      "Epoch: 10 | Time: 0.0m 28.15s\n",
      "\tTrain Loss: 0.494\n",
      "\t Val. Loss: 1.059\n",
      "\t Val. Accuracy: 0.350\n",
      "Epoch: 11 | Time: 0.0m 28.06s\n",
      "\tTrain Loss: 0.461\n",
      "\t Val. Loss: 1.056\n",
      "\t Val. Accuracy: 0.353\n",
      "Epoch: 12 | Time: 0.0m 28.15s\n",
      "\tTrain Loss: 0.427\n",
      "\t Val. Loss: 1.053\n",
      "\t Val. Accuracy: 0.365\n",
      "Epoch: 13 | Time: 0.0m 28.26s\n",
      "\tTrain Loss: 0.393\n",
      "\t Val. Loss: 1.126\n",
      "\t Val. Accuracy: 0.350\n",
      "Epoch: 14 | Time: 0.0m 28.12s\n",
      "\tTrain Loss: 0.363\n",
      "\t Val. Loss: 1.081\n",
      "\t Val. Accuracy: 0.374\n",
      "Epoch: 15 | Time: 0.0m 27.99s\n",
      "\tTrain Loss: 0.337\n",
      "\t Val. Loss: 1.117\n",
      "\t Val. Accuracy: 0.364\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>14</td></tr><tr><td>train_loss</td><td>0.3369</td></tr><tr><td>val_accuracy</td><td>0.3637</td></tr><tr><td>val_loss</td><td>1.11681</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">GRU_enc_3_dec_2_hdim_512_emb_256_bs_64_drop_0.3_beam_1_lr_0.0001_clip_5_tf_0.5_epoch_15</strong> at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/03u4qjpd' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3/runs/03u4qjpd</a><br> View project at: <a href='https://wandb.ai/cs24m033-iit-madras/DA6401-A3' target=\"_blank\">https://wandb.ai/cs24m033-iit-madras/DA6401-A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250520_080117-03u4qjpd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "wandb.login()\n",
    "sweep_id = wandb.sweep(sweep_config,project=\"DA6401-A3\", entity=\"cs24m033-iit-madras\")\n",
    "wandb.agent(sweep_id,function=run_sweep, count = 22 )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7460854,
     "sourceId": 11872028,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
